openapi: 3.1.0
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  version: 2.3.0
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
servers:
- url: https://api.openai.com/v1
paths:
  /responses:
    post:
      operationId: createResponse
      tags:
      - Responses
      summary: Create a model response
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
      x-oaiMeta:
        name: Create a model response
        group: responses
        returns: 'Returns a [Response](https://platform.openai.com/docs/api-reference/responses/object)
          object.

          '
        path: create
        examples:
        - title: Text input
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"input\": \"Tell me\
              \ a three sentence bedtime story about a unicorn.\"\n  }'\n"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    input: \"Tell me a three sentence bedtime story about a unicorn.\"\
              \n});\n\nconsole.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            csharp: "using System;\nusing OpenAI.Responses;\n\nOpenAIResponseClient\
              \ client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nOpenAIResponse response = client.CreateResponse(\"\
              Tell me a three sentence bedtime story about a unicorn.\");\n\nConsole.WriteLine(response.GetOutputText());\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741476542,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            message\",\n      \"id\": \"msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b\"\
            ,\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n\
            \      \"content\": [\n        {\n          \"type\": \"output_text\"\
            ,\n          \"text\": \"In a peaceful grove beneath a silver moon, a\
            \ unicorn named Lumina discovered a hidden pool that reflected the stars.\
            \ As she dipped her horn into the water, the pool began to shimmer, revealing\
            \ a pathway to a magical realm of endless night skies. Filled with wonder,\
            \ Lumina whispered a wish for all who dream to find their own hidden magic,\
            \ and as she glanced back, her hoofprints sparkled like stardust.\",\n\
            \          \"annotations\": []\n        }\n      ]\n    }\n  ],\n  \"\
            parallel_tool_calls\": true,\n  \"previous_response_id\": null,\n  \"\
            reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n  },\n \
            \ \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n    \"format\"\
            : {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\"\
            ,\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\"\
            ,\n  \"usage\": {\n    \"input_tokens\": 36,\n    \"input_tokens_details\"\
            : {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 87,\n\
            \    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n   \
            \ },\n    \"total_tokens\": 123\n  },\n  \"user\": null,\n  \"metadata\"\
            : {}\n}\n"
        - title: Image input
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"input\": [\n     \
              \ {\n        \"role\": \"user\",\n        \"content\": [\n         \
              \ {\"type\": \"input_text\", \"text\": \"what is in this image?\"},\n\
              \          {\n            \"type\": \"input_image\",\n            \"\
              image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              \n          }\n        ]\n      }\n    ]\n  }'\n"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    input: [\n        {\n            role: \"user\",\n          \
              \  content: [\n                { type: \"input_text\", text: \"what\
              \ is in this image?\" },\n                {\n                    type:\
              \ \"input_image\",\n                    image_url:\n               \
              \         \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              ,\n                },\n            ],\n        },\n    ],\n});\n\nconsole.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            csharp: "using System;\nusing System.Collections.Generic;\n\nusing OpenAI.Responses;\n\
              \nOpenAIResponseClient client = new(\n    model: \"gpt-4.1\",\n    apiKey:\
              \ Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\")\n);\n\nList<ResponseItem>\
              \ inputItems =\n[\n    ResponseItem.CreateUserMessageItem(\n       \
              \ [\n            ResponseContentPart.CreateInputTextPart(\"What is in\
              \ this image?\"),\n            ResponseContentPart.CreateInputImagePart(new\
              \ Uri(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              ))\n        ]\n    )\n];\n\nOpenAIResponse response = client.CreateResponse(inputItems);\n\
              \nConsole.WriteLine(response.GetOutputText());\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741476777,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            message\",\n      \"id\": \"msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41\"\
            ,\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n\
            \      \"content\": [\n        {\n          \"type\": \"output_text\"\
            ,\n          \"text\": \"The image depicts a scenic landscape with a wooden\
            \ boardwalk or pathway leading through lush, green grass under a blue\
            \ sky with some clouds. The setting suggests a peaceful natural area,\
            \ possibly a park or nature reserve. There are trees and shrubs in the\
            \ background.\",\n          \"annotations\": []\n        }\n      ]\n\
            \    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\"\
            : null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n\
            \  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n  \
            \  \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\"\
            : \"auto\",\n  \"tools\": [],\n  \"top_p\": 1.0,\n  \"truncation\": \"\
            disabled\",\n  \"usage\": {\n    \"input_tokens\": 328,\n    \"input_tokens_details\"\
            : {\n      \"cached_tokens\": 0\n    },\n    \"output_tokens\": 52,\n\
            \    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n   \
            \ },\n    \"total_tokens\": 380\n  },\n  \"user\": null,\n  \"metadata\"\
            : {}\n}\n"
        - title: File input
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"input\": [\n     \
              \ {\n        \"role\": \"user\",\n        \"content\": [\n         \
              \ {\"type\": \"input_text\", \"text\": \"what is in this file?\"},\n\
              \          {\n            \"type\": \"input_file\",\n            \"\
              file_url\": \"https://www.berkshirehathaway.com/letters/2024ltr.pdf\"\
              \n          }\n        ]\n      }\n    ]\n  }'\n"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    input: [\n        {\n            role: \"user\",\n          \
              \  content: [\n                { type: \"input_text\", text: \"what\
              \ is in this file?\" },\n                {\n                    type:\
              \ \"input_file\",\n                    file_url: \"https://www.berkshirehathaway.com/letters/2024ltr.pdf\"\
              ,\n                },\n            ],\n        },\n    ],\n});\n\nconsole.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_686eef60237881a2bd1180bb8b13de430e34c516d176ff86\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1752100704,\n  \"status\"\
            : \"completed\",\n  \"background\": false,\n  \"error\": null,\n  \"incomplete_details\"\
            : null,\n  \"instructions\": null,\n  \"max_output_tokens\": null,\n \
            \ \"max_tool_calls\": null,\n  \"model\": \"gpt-4.1-2025-04-14\",\n  \"\
            output\": [\n    {\n      \"id\": \"msg_686eef60d3e081a29283bdcbc4322fd90e34c516d176ff86\"\
            ,\n      \"type\": \"message\",\n      \"status\": \"completed\",\n  \
            \    \"content\": [\n        {\n          \"type\": \"output_text\",\n\
            \          \"annotations\": [],\n          \"logprobs\": [],\n       \
            \   \"text\": \"The file seems to contain excerpts from a letter to the\
            \ shareholders of Berkshire Hathaway Inc., likely written by Warren Buffett.\
            \ It covers several topics:\\n\\n1. **Communication Philosophy**: Buffett\
            \ emphasizes the importance of transparency and candidness in reporting\
            \ mistakes and successes to shareholders.\\n\\n2. **Mistakes and Learnings**:\
            \ The letter acknowledges past mistakes in business assessments and management\
            \ hires, highlighting the importance of correcting errors promptly.\\\
            n\\n3. **CEO Succession**: Mention of Greg Abel stepping in as the new\
            \ CEO and continuing the tradition of honest communication.\\n\\n4. **Pete\
            \ Liegl Story**: A detailed account of acquiring Forest River and the\
            \ relationship with its founder, highlighting trust and effective business\
            \ decisions.\\n\\n5. **2024 Performance**: Overview of business performance,\
            \ particularly in insurance and investment activities, with a focus on\
            \ GEICO's improvement.\\n\\n6. **Tax Contributions**: Discussion of significant\
            \ tax payments to the U.S. Treasury, credited to shareholders' reinvestments.\\\
            n\\n7. **Investment Strategy**: A breakdown of Berkshire\\u2019s investments\
            \ in both controlled subsidiaries and marketable equities, along with\
            \ a focus on long-term holding strategies.\\n\\n8. **American Capitalism**:\
            \ Reflections on America\\u2019s economic development and Berkshire\\\
            u2019s role within it.\\n\\n9. **Property-Casualty Insurance**: Insights\
            \ into the P/C insurance business model and its challenges and benefits.\\\
            n\\n10. **Japanese Investments**: Information about Berkshire\\u2019s\
            \ investments in Japanese companies and future plans.\\n\\n11. **Annual\
            \ Meeting**: Details about the upcoming annual gathering in Omaha, including\
            \ schedule changes and new book releases.\\n\\n12. **Personal Anecdotes**:\
            \ Light-hearted stories about family and interactions, conveying Buffett's\
            \ personable approach.\\n\\n13. **Financial Performance Data**: Tables\
            \ comparing Berkshire\\u2019s annual performance to the S&P 500, showing\
            \ impressive long-term gains.\\n\\nOverall, the letter reinforces Berkshire\
            \ Hathaway's commitment to transparency, investment in both its businesses\
            \ and the wider economy, and emphasizes strong leadership and prudent\
            \ financial management.\"\n        }\n      ],\n      \"role\": \"assistant\"\
            \n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\"\
            : null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n\
            \  },\n  \"service_tier\": \"default\",\n  \"store\": true,\n  \"temperature\"\
            : 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n \
            \   }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n  \"top_logprobs\"\
            : 0,\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\"\
            : {\n    \"input_tokens\": 8438,\n    \"input_tokens_details\": {\n  \
            \    \"cached_tokens\": 0\n    },\n    \"output_tokens\": 398,\n    \"\
            output_tokens_details\": {\n      \"reasoning_tokens\": 0\n    },\n  \
            \  \"total_tokens\": 8836\n  },\n  \"user\": null,\n  \"metadata\": {}\n\
            }\n"
        - title: Web search
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"tools\": [{ \"type\"\
              : \"web_search_preview\" }],\n    \"input\": \"What was a positive news\
              \ story from today?\"\n  }'\n"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    tools: [{ type: \"web_search_preview\" }],\n    input: \"What\
              \ was a positive news story from today?\",\n});\n\nconsole.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            csharp: "using System;\n\nusing OpenAI.Responses;\n\nOpenAIResponseClient\
              \ client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nstring userInputText = \"What was a positive\
              \ news story from today?\";\n\nResponseCreationOptions options = new()\n\
              {\n    Tools =\n    {\n        ResponseTool.CreateWebSearchTool()\n\
              \    },\n};\n\nOpenAIResponse response = client.CreateResponse(userInputText,\
              \ options);\n\nConsole.WriteLine(response.GetOutputText());\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741484430,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            web_search_call\",\n      \"id\": \"ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c\"\
            ,\n      \"status\": \"completed\"\n    },\n    {\n      \"type\": \"\
            message\",\n      \"id\": \"msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c\"\
            ,\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n\
            \      \"content\": [\n        {\n          \"type\": \"output_text\"\
            ,\n          \"text\": \"As of today, March 9, 2025, one notable positive\
            \ news story...\",\n          \"annotations\": [\n            {\n    \
            \          \"type\": \"url_citation\",\n              \"start_index\"\
            : 442,\n              \"end_index\": 557,\n              \"url\": \"https://.../?utm_source=chatgpt.com\"\
            ,\n              \"title\": \"...\"\n            },\n            {\n \
            \             \"type\": \"url_citation\",\n              \"start_index\"\
            : 962,\n              \"end_index\": 1077,\n              \"url\": \"\
            https://.../?utm_source=chatgpt.com\",\n              \"title\": \"...\"\
            \n            },\n            {\n              \"type\": \"url_citation\"\
            ,\n              \"start_index\": 1336,\n              \"end_index\":\
            \ 1451,\n              \"url\": \"https://.../?utm_source=chatgpt.com\"\
            ,\n              \"title\": \"...\"\n            }\n          ]\n    \
            \    }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\"\
            : null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n\
            \  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n  \
            \  \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\"\
            : \"auto\",\n  \"tools\": [\n    {\n      \"type\": \"web_search_preview\"\
            ,\n      \"domains\": [],\n      \"search_context_size\": \"medium\",\n\
            \      \"user_location\": {\n        \"type\": \"approximate\",\n    \
            \    \"city\": null,\n        \"country\": \"US\",\n        \"region\"\
            : null,\n        \"timezone\": null\n      }\n    }\n  ],\n  \"top_p\"\
            : 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\"\
            : 328,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n\
            \    },\n    \"output_tokens\": 356,\n    \"output_tokens_details\": {\n\
            \      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 684\n  },\n\
            \  \"user\": null,\n  \"metadata\": {}\n}\n"
        - title: File search
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"tools\": [{\n    \
              \  \"type\": \"file_search\",\n      \"vector_store_ids\": [\"vs_1234567890\"\
              ],\n      \"max_num_results\": 20\n    }],\n    \"input\": \"What are\
              \ the attributes of an ancient brown dragon?\"\n  }'\n"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    tools: [{\n      type: \"file_search\",\n      vector_store_ids:\
              \ [\"vs_1234567890\"],\n      max_num_results: 20\n    }],\n    input:\
              \ \"What are the attributes of an ancient brown dragon?\",\n});\n\n\
              console.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            csharp: "using System;\n\nusing OpenAI.Responses;\n\nOpenAIResponseClient\
              \ client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nstring userInputText = \"What are the attributes\
              \ of an ancient brown dragon?\";\n\nResponseCreationOptions options\
              \ = new()\n{\n    Tools =\n    {\n        ResponseTool.CreateFileSearchTool(\n\
              \            vectorStoreIds: [\"vs_1234567890\"],\n            maxResultCount:\
              \ 20\n        )\n    },\n};\n\nOpenAIResponse response = client.CreateResponse(userInputText,\
              \ options);\n\nConsole.WriteLine(response.GetOutputText());\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741485253,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            file_search_call\",\n      \"id\": \"fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7\"\
            ,\n      \"status\": \"completed\",\n      \"queries\": [\n        \"\
            attributes of an ancient brown dragon\"\n      ],\n      \"results\":\
            \ null\n    },\n    {\n      \"type\": \"message\",\n      \"id\": \"\
            msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7\",\n      \"status\"\
            : \"completed\",\n      \"role\": \"assistant\",\n      \"content\": [\n\
            \        {\n          \"type\": \"output_text\",\n          \"text\":\
            \ \"The attributes of an ancient brown dragon include...\",\n        \
            \  \"annotations\": [\n            {\n              \"type\": \"file_citation\"\
            ,\n              \"index\": 320,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 576,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 815,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1030,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1156,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            },\n     \
            \       {\n              \"type\": \"file_citation\",\n              \"\
            index\": 1225,\n              \"file_id\": \"file-4wDz5b167pAf72nx1h9eiN\"\
            ,\n              \"filename\": \"dragons.pdf\"\n            }\n      \
            \    ]\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\": true,\n\
            \  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"effort\"\
            : null,\n    \"summary\": null\n  },\n  \"store\": true,\n  \"temperature\"\
            : 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\": \"text\"\n \
            \   }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [\n    {\n   \
            \   \"type\": \"file_search\",\n      \"filters\": null,\n      \"max_num_results\"\
            : 20,\n      \"ranking_options\": {\n        \"ranker\": \"auto\",\n \
            \       \"score_threshold\": 0.0\n      },\n      \"vector_store_ids\"\
            : [\n        \"vs_1234567890\"\n      ]\n    }\n  ],\n  \"top_p\": 1.0,\n\
            \  \"truncation\": \"disabled\",\n  \"usage\": {\n    \"input_tokens\"\
            : 18307,\n    \"input_tokens_details\": {\n      \"cached_tokens\": 0\n\
            \    },\n    \"output_tokens\": 348,\n    \"output_tokens_details\": {\n\
            \      \"reasoning_tokens\": 0\n    },\n    \"total_tokens\": 18655\n\
            \  },\n  \"user\": null,\n  \"metadata\": {}\n}      \n"
        - title: Streaming
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"instructions\": \"\
              You are a helpful assistant.\",\n    \"input\": \"Hello!\",\n    \"\
              stream\": true\n  }'\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"gpt-4.1\"\
              ,\n    instructions: \"You are a helpful assistant.\",\n    input: \"\
              Hello!\",\n    stream: true,\n});\n\nfor await (const event of response)\
              \ {\n    console.log(event);\n}\n"
            csharp: "using System;\nusing System.ClientModel;\nusing System.Threading.Tasks;\n\
              \nusing OpenAI.Responses;\n\nOpenAIResponseClient client = new(\n  \
              \  model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nstring userInputText = \"Hello!\";\n\nResponseCreationOptions\
              \ options = new()\n{\n    Instructions = \"You are a helpful assistant.\"\
              ,\n};\n\nAsyncCollectionResult<StreamingResponseUpdate> responseUpdates\
              \ = client.CreateResponseStreamingAsync(userInputText, options);\n\n\
              await foreach (StreamingResponseUpdate responseUpdate in responseUpdates)\n\
              {\n    if (responseUpdate is StreamingResponseOutputTextDeltaUpdate\
              \ outputTextDeltaUpdate)\n    {\n        Console.Write(outputTextDeltaUpdate.Delta);\n\
              \    }\n}\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: 'event: response.created

            data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You
            are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}


            event: response.in_progress

            data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You
            are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}


            event: response.output_item.added

            data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}


            event: response.content_part.added

            data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}


            event: response.output_text.delta

            data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}


            ...


            event: response.output_text.done

            data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi
            there! How can I assist you today?"}


            event: response.content_part.done

            data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi
            there! How can I assist you today?","annotations":[]}}


            event: response.output_item.done

            data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi
            there! How can I assist you today?","annotations":[]}]}}


            event: response.completed

            data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You
            are a helpful assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi
            there! How can I assist you today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}

            '
        - title: Functions
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4.1\",\n    \"input\": \"What is\
              \ the weather like in Boston today?\",\n    \"tools\": [\n      {\n\
              \        \"type\": \"function\",\n        \"name\": \"get_current_weather\"\
              ,\n        \"description\": \"Get the current weather in a given location\"\
              ,\n        \"parameters\": {\n          \"type\": \"object\",\n    \
              \      \"properties\": {\n            \"location\": {\n            \
              \  \"type\": \"string\",\n              \"description\": \"The city\
              \ and state, e.g. San Francisco, CA\"\n            },\n            \"\
              unit\": {\n              \"type\": \"string\",\n              \"enum\"\
              : [\"celsius\", \"fahrenheit\"]\n            }\n          },\n     \
              \     \"required\": [\"location\", \"unit\"]\n        }\n      }\n \
              \   ],\n    \"tool_choice\": \"auto\"\n  }'\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            javascript: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst tools = [\n    {\n        type: \"function\",\n        name:\
              \ \"get_current_weather\",\n        description: \"Get the current weather\
              \ in a given location\",\n        parameters: {\n            type: \"\
              object\",\n            properties: {\n                location: {\n\
              \                    type: \"string\",\n                    description:\
              \ \"The city and state, e.g. San Francisco, CA\",\n                },\n\
              \                unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"\
              ] },\n            },\n            required: [\"location\", \"unit\"\
              ],\n        },\n    },\n];\n\nconst response = await openai.responses.create({\n\
              \    model: \"gpt-4.1\",\n    tools: tools,\n    input: \"What is the\
              \ weather like in Boston today?\",\n    tool_choice: \"auto\",\n});\n\
              \nconsole.log(response);\n"
            csharp: "using System;\nusing OpenAI.Responses;\n\nOpenAIResponseClient\
              \ client = new(\n    model: \"gpt-4.1\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nResponseTool getCurrentWeatherFunctionTool\
              \ = ResponseTool.CreateFunctionTool(\n    functionName: \"get_current_weather\"\
              ,\n    functionDescription: \"Get the current weather in a given location\"\
              ,\n    functionParameters: BinaryData.FromString(\"\"\"\n        {\n\
              \            \"type\": \"object\",\n            \"properties\": {\n\
              \                \"location\": {\n                    \"type\": \"string\"\
              ,\n                    \"description\": \"The city and state, e.g. San\
              \ Francisco, CA\"\n                },\n                \"unit\": {\"\
              type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n     \
              \       },\n            \"required\": [\"location\", \"unit\"]\n   \
              \     }\n        \"\"\"\n    )\n);\n\nstring userInputText = \"What\
              \ is the weather like in Boston today?\";\n\nResponseCreationOptions\
              \ options = new()\n{\n    Tools =\n    {\n        getCurrentWeatherFunctionTool\n\
              \    },\n    ToolChoice = ResponseToolChoice.CreateAutoChoice(),\n};\n\
              \nOpenAIResponse response = client.CreateResponse(userInputText, options);\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741294021,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"gpt-4.1-2025-04-14\",\n  \"output\": [\n    {\n      \"type\": \"\
            function_call\",\n      \"id\": \"fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0\"\
            ,\n      \"call_id\": \"call_unLAR8MvFNptuiZK6K6HCy5k\",\n      \"name\"\
            : \"get_current_weather\",\n      \"arguments\": \"{\\\"location\\\":\\\
            \"Boston, MA\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n      \"status\": \"\
            completed\"\n    }\n  ],\n  \"parallel_tool_calls\": true,\n  \"previous_response_id\"\
            : null,\n  \"reasoning\": {\n    \"effort\": null,\n    \"summary\": null\n\
            \  },\n  \"store\": true,\n  \"temperature\": 1.0,\n  \"text\": {\n  \
            \  \"format\": {\n      \"type\": \"text\"\n    }\n  },\n  \"tool_choice\"\
            : \"auto\",\n  \"tools\": [\n    {\n      \"type\": \"function\",\n  \
            \    \"description\": \"Get the current weather in a given location\"\
            ,\n      \"name\": \"get_current_weather\",\n      \"parameters\": {\n\
            \        \"type\": \"object\",\n        \"properties\": {\n          \"\
            location\": {\n            \"type\": \"string\",\n            \"description\"\
            : \"The city and state, e.g. San Francisco, CA\"\n          },\n     \
            \     \"unit\": {\n            \"type\": \"string\",\n            \"enum\"\
            : [\n              \"celsius\",\n              \"fahrenheit\"\n      \
            \      ]\n          }\n        },\n        \"required\": [\n         \
            \ \"location\",\n          \"unit\"\n        ]\n      },\n      \"strict\"\
            : true\n    }\n  ],\n  \"top_p\": 1.0,\n  \"truncation\": \"disabled\"\
            ,\n  \"usage\": {\n    \"input_tokens\": 291,\n    \"output_tokens\":\
            \ 23,\n    \"output_tokens_details\": {\n      \"reasoning_tokens\": 0\n\
            \    },\n    \"total_tokens\": 314\n  },\n  \"user\": null,\n  \"metadata\"\
            : {}\n}\n"
        - title: Reasoning
          request:
            curl: "curl https://api.openai.com/v1/responses \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"o3-mini\",\n    \"input\": \"How much\
              \ wood would a woodchuck chuck?\",\n    \"reasoning\": {\n      \"effort\"\
              : \"high\"\n    }\n  }'\n"
            javascript: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nconst response = await openai.responses.create({\n    model: \"o3-mini\"\
              ,\n    input: \"How much wood would a woodchuck chuck?\",\n    reasoning:\
              \ {\n      effort: \"high\"\n    }\n});\n\nconsole.log(response);\n"
            python: "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"\
              My API Key\",\n)\nresponse = client.responses.create()\nprint(response.id)"
            csharp: "using System;\nusing OpenAI.Responses;\n\nOpenAIResponseClient\
              \ client = new(\n    model: \"o3-mini\",\n    apiKey: Environment.GetEnvironmentVariable(\"\
              OPENAI_API_KEY\")\n);\n\nstring userInputText = \"How much wood would\
              \ a woodchuck chuck?\";\n\nResponseCreationOptions options = new()\n\
              {\n    ReasoningOptions = new()\n    {\n        ReasoningEffortLevel\
              \ = ResponseReasoningEffortLevel.High,\n    },\n};\n\nOpenAIResponse\
              \ response = client.CreateResponse(userInputText, options);\n\nConsole.WriteLine(response.GetOutputText());\n"
            node.js: "import OpenAI from 'openai';\n\nconst client = new OpenAI({\n\
              \  apiKey: 'My API Key',\n});\n\nconst response = await client.responses.create();\n\
              \nconsole.log(response.id);"
            go: "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/openai/openai-go\"\
              \n  \"github.com/openai/openai-go/option\"\n  \"github.com/openai/openai-go/responses\"\
              \n)\n\nfunc main() {\n  client := openai.NewClient(\n    option.WithAPIKey(\"\
              My API Key\"),\n  )\n  response, err := client.Responses.New(context.TODO(),\
              \ responses.ResponseNewParams{\n\n  })\n  if err != nil {\n    panic(err.Error())\n\
              \  }\n  fmt.Printf(\"%+v\\n\", response.ID)\n}\n"
            java: "package com.openai.example;\n\nimport com.openai.client.OpenAIClient;\n\
              import com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.responses.Response;\n\
              import com.openai.models.responses.ResponseCreateParams;\n\npublic final\
              \ class Main {\n    private Main() {}\n\n    public static void main(String[]\
              \ args) {\n        OpenAIClient client = OpenAIOkHttpClient.fromEnv();\n\
              \n        Response response = client.responses().create();\n    }\n}"
            ruby: 'require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              response = openai.responses.create


              puts(response)'
          response: "{\n  \"id\": \"resp_67ccd7eca01881908ff0b5146584e408072912b2993db808\"\
            ,\n  \"object\": \"response\",\n  \"created_at\": 1741477868,\n  \"status\"\
            : \"completed\",\n  \"error\": null,\n  \"incomplete_details\": null,\n\
            \  \"instructions\": null,\n  \"max_output_tokens\": null,\n  \"model\"\
            : \"o1-2024-12-17\",\n  \"output\": [\n    {\n      \"type\": \"message\"\
            ,\n      \"id\": \"msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808\"\
            ,\n      \"status\": \"completed\",\n      \"role\": \"assistant\",\n\
            \      \"content\": [\n        {\n          \"type\": \"output_text\"\
            ,\n          \"text\": \"The classic tongue twister...\",\n          \"\
            annotations\": []\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\"\
            : true,\n  \"previous_response_id\": null,\n  \"reasoning\": {\n    \"\
            effort\": \"high\",\n    \"summary\": null\n  },\n  \"store\": true,\n\
            \  \"temperature\": 1.0,\n  \"text\": {\n    \"format\": {\n      \"type\"\
            : \"text\"\n    }\n  },\n  \"tool_choice\": \"auto\",\n  \"tools\": [],\n\
            \  \"top_p\": 1.0,\n  \"truncation\": \"disabled\",\n  \"usage\": {\n\
            \    \"input_tokens\": 81,\n    \"input_tokens_details\": {\n      \"\
            cached_tokens\": 0\n    },\n    \"output_tokens\": 1035,\n    \"output_tokens_details\"\
            : {\n      \"reasoning_tokens\": 832\n    },\n    \"total_tokens\": 1116\n\
            \  },\n  \"user\": null,\n  \"metadata\": {}\n}\n"
      description: 'Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text)
        or

        [image](https://platform.openai.com/docs/guides/images) inputs to generate
        [text](https://platform.openai.com/docs/guides/text)

        or [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs.
        Have the model call

        your own [custom code](https://platform.openai.com/docs/guides/function-calling)
        or use built-in

        [tools](https://platform.openai.com/docs/guides/tools) like [web search](https://platform.openai.com/docs/guides/tools-web-search)

        or [file search](https://platform.openai.com/docs/guides/tools-file-search)
        to use your own data

        as input for the model''s response.

        '
components:
  schemas:
    CodeInterpreterTool:
      type: object
      title: Code interpreter
      description: 'A tool that runs Python code to help generate a response to a
        prompt.

        '
      properties:
        type:
          type: string
          enum:
          - code_interpreter
          description: 'The type of the code interpreter tool. Always `code_interpreter`.

            '
          x-stainless-const: true
        container:
          description: 'The code interpreter container. Can be a container ID or an
            object that

            specifies uploaded file IDs to make available to your code.

            '
          anyOf:
          - type: string
            description: The container ID.
          - $ref: '#/components/schemas/CodeInterpreterContainerAuto'
      required:
      - type
      - container
    CodeInterpreterToolCall:
      type: object
      title: Code interpreter tool call
      description: 'A tool call to run code.

        '
      properties:
        type:
          type: string
          enum:
          - code_interpreter_call
          default: code_interpreter_call
          x-stainless-const: true
          description: 'The type of the code interpreter tool call. Always `code_interpreter_call`.

            '
        id:
          type: string
          description: 'The unique ID of the code interpreter tool call.

            '
        status:
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
          - interpreting
          - failed
          description: 'The status of the code interpreter tool call. Valid values
            are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.

            '
        container_id:
          type: string
          description: 'The ID of the container used to run the code.

            '
        code:
          anyOf:
          - type: string
            description: 'The code to run, or null if not available.

              '
          - type: 'null'
        outputs:
          anyOf:
          - type: array
            items:
              discriminator:
                propertyName: type
              anyOf:
              - $ref: '#/components/schemas/CodeInterpreterOutputLogs'
              - $ref: '#/components/schemas/CodeInterpreterOutputImage'
            discriminator:
              propertyName: type
            description: 'The outputs generated by the code interpreter, such as logs
              or images.

              Can be null if no outputs are available.

              '
          - type: 'null'
      required:
      - type
      - id
      - status
      - container_id
      - code
      - outputs
    ComparisonFilter:
      type: object
      additionalProperties: false
      title: Comparison Filter
      description: 'A filter used to compare a specified attribute key to a given
        value using a defined comparison operation.

        '
      properties:
        type:
          type: string
          default: eq
          enum:
          - eq
          - ne
          - gt
          - gte
          - lt
          - lte
          description: 'Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`,
            `lt`, `lte`, `in`, `nin`.

            - `eq`: equals

            - `ne`: not equal

            - `gt`: greater than

            - `gte`: greater than or equal

            - `lt`: less than

            - `lte`: less than or equal

            - `in`: in

            - `nin`: not in

            '
        key:
          type: string
          description: The key to compare against the value.
        value:
          description: The value to compare against the attribute key; supports string,
            number, or boolean types.
          anyOf:
          - type: string
          - type: number
          - type: boolean
          - type: array
            items:
              $ref: '#/components/schemas/ComparisonFilterValueItems'
      required:
      - type
      - key
      - value
      x-oaiMeta:
        name: ComparisonFilter
    CompoundFilter:
      $recursiveAnchor: true
      type: object
      additionalProperties: false
      title: Compound Filter
      description: Combine multiple filters using `and` or `or`.
      properties:
        type:
          type: string
          description: 'Type of operation: `and` or `or`.'
          enum:
          - and
          - or
        filters:
          type: array
          description: Array of filters to combine. Items can be `ComparisonFilter`
            or `CompoundFilter`.
          items:
            discriminator:
              propertyName: type
            anyOf:
            - $ref: '#/components/schemas/ComparisonFilter'
            - $recursiveRef: '#'
      required:
      - type
      - filters
      x-oaiMeta:
        name: CompoundFilter
    ComputerAction:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/ClickParam'
      - $ref: '#/components/schemas/DoubleClickAction'
      - $ref: '#/components/schemas/Drag'
      - $ref: '#/components/schemas/KeyPressAction'
      - $ref: '#/components/schemas/Move'
      - $ref: '#/components/schemas/Screenshot'
      - $ref: '#/components/schemas/Scroll'
      - $ref: '#/components/schemas/Type'
      - $ref: '#/components/schemas/Wait'
    ComputerScreenshotImage:
      type: object
      description: 'A computer screenshot image used with the computer use tool.

        '
      properties:
        type:
          type: string
          enum:
          - computer_screenshot
          default: computer_screenshot
          description: "Specifies the event type. For a computer screenshot, this\
            \ property is \nalways set to `computer_screenshot`.\n"
          x-stainless-const: true
        image_url:
          type: string
          description: The URL of the screenshot image.
        file_id:
          type: string
          description: The identifier of an uploaded file that contains the screenshot.
      required:
      - type
    ComputerToolCall:
      type: object
      title: Computer tool call
      description: 'A tool call to a computer use tool. See the

        [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use)
        for more information.

        '
      properties:
        type:
          type: string
          description: The type of the computer call. Always `computer_call`.
          enum:
          - computer_call
          default: computer_call
        id:
          type: string
          description: The unique ID of the computer call.
        call_id:
          type: string
          description: 'An identifier used when responding to the tool call with output.

            '
        action:
          $ref: '#/components/schemas/ComputerAction'
        pending_safety_checks:
          type: array
          items:
            $ref: '#/components/schemas/ComputerCallSafetyCheckParam'
          description: 'The pending safety checks for the computer call.

            '
        status:
          type: string
          description: 'The status of the item. One of `in_progress`, `completed`,
            or

            `incomplete`. Populated when items are returned via API.

            '
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - type
      - id
      - action
      - call_id
      - pending_safety_checks
      - status
    ConversationParam:
      description: 'The conversation that this response belongs to. Items from this
        conversation are prepended to `input_items` for this response request.

        Input items and output items from this response are automatically added to
        this conversation after this response completes.

        '
      anyOf:
      - type: string
        title: Conversation ID
        description: 'The unique ID of the conversation.

          '
      - $ref: '#/components/schemas/ConversationParam-2'
    CreateModelResponseProperties:
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
      - type: object
        properties:
          top_logprobs:
            description: 'An integer between 0 and 20 specifying the number of most
              likely tokens to

              return at each token position, each with an associated log probability.

              '
            type: integer
            minimum: 0
            maximum: 20
    CreateResponse:
      allOf:
      - $ref: '#/components/schemas/CreateModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - type: object
        properties:
          input:
            $ref: '#/components/schemas/InputParam'
          include:
            anyOf:
            - type: array
              description: 'Specify additional output data to include in the model
                response. Currently supported values are:

                - `web_search_call.action.sources`: Include the sources of the web
                search tool call.

                - `code_interpreter_call.outputs`: Includes the outputs of python
                code execution in code interpreter tool call items.

                - `computer_call_output.output.image_url`: Include image urls from
                the computer call output.

                - `file_search_call.results`: Include the search results of the file
                search tool call.

                - `message.input_image.image_url`: Include image urls from the input
                message.

                - `message.output_text.logprobs`: Include logprobs with assistant
                messages.

                - `reasoning.encrypted_content`: Includes an encrypted version of
                reasoning tokens in reasoning item outputs. This enables reasoning
                items to be used in multi-turn conversations when using the Responses
                API statelessly (like when the `store` parameter is set to `false`,
                or when an organization is enrolled in the zero data retention program).'
              items:
                $ref: '#/components/schemas/IncludeEnum'
            - type: 'null'
          parallel_tool_calls:
            anyOf:
            - type: boolean
              description: 'Whether to allow the model to run tool calls in parallel.

                '
              default: true
            - type: 'null'
          store:
            anyOf:
            - type: boolean
              description: 'Whether to store the generated model response for later
                retrieval via

                API.

                '
              default: true
            - type: 'null'
          instructions:
            anyOf:
            - type: string
              description: 'A system (or developer) message inserted into the model''s
                context.


                When using along with `previous_response_id`, the instructions from
                a previous

                response will not be carried over to the next response. This makes
                it simple

                to swap out system (or developer) messages in new responses.

                '
            - type: 'null'
          stream:
            anyOf:
            - description: 'If set to true, the model response data will be streamed
                to the client

                as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).

                See the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)

                for more information.

                '
              type: boolean
              default: false
            - type: 'null'
          stream_options:
            $ref: '#/components/schemas/ResponseStreamOptions'
          conversation:
            anyOf:
            - $ref: '#/components/schemas/ConversationParam'
            - type: 'null'
    CustomToolCall:
      type: object
      title: Custom tool call
      description: 'A call to a custom tool created by the model.

        '
      properties:
        type:
          type: string
          enum:
          - custom_tool_call
          x-stainless-const: true
          description: 'The type of the custom tool call. Always `custom_tool_call`.

            '
        id:
          type: string
          description: 'The unique ID of the custom tool call in the OpenAI platform.

            '
        call_id:
          type: string
          description: 'An identifier used to map this custom tool call to a tool
            call output.

            '
        name:
          type: string
          description: 'The name of the custom tool being called.

            '
        input:
          type: string
          description: 'The input for the custom tool call generated by the model.

            '
      required:
      - type
      - call_id
      - name
      - input
    CustomToolCallOutput:
      type: object
      title: Custom tool call output
      description: 'The output of a custom tool call from your code, being sent back
        to the model.

        '
      properties:
        type:
          type: string
          enum:
          - custom_tool_call_output
          x-stainless-const: true
          description: 'The type of the custom tool call output. Always `custom_tool_call_output`.

            '
        id:
          type: string
          description: 'The unique ID of the custom tool call output in the OpenAI
            platform.

            '
        call_id:
          type: string
          description: 'The call ID, used to map this custom tool call output to a
            custom tool call.

            '
        output:
          description: 'The output from the custom tool call generated by your code.

            Can be a string or an list of output content.

            '
          anyOf:
          - type: string
            description: 'A string of the output of the custom tool call.

              '
            title: string output
          - type: array
            items:
              $ref: '#/components/schemas/FunctionAndCustomToolCallOutput'
            title: output content list
            description: 'Text, image, or file output of the custom tool call.

              '
      required:
      - type
      - call_id
      - output
    Drag:
      type: object
      title: Drag
      description: 'A drag action.

        '
      properties:
        type:
          type: string
          enum:
          - drag
          default: drag
          description: "Specifies the event type. For a drag action, this property\
            \ is \nalways set to `drag`.\n"
          x-stainless-const: true
        path:
          type: array
          description: "An array of coordinates representing the path of the drag\
            \ action. Coordinates will appear as an array\nof objects, eg\n```\n[\n\
            \  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n"
          items:
            $ref: '#/components/schemas/DragPoint'
      required:
      - type
      - path
    EasyInputMessage:
      type: object
      title: Input message
      description: 'A message input to the model with a role indicating instruction
        following

        hierarchy. Instructions given with the `developer` or `system` role take

        precedence over instructions given with the `user` role. Messages with the

        `assistant` role are presumed to have been generated by the model in previous

        interactions.

        '
      properties:
        role:
          type: string
          description: 'The role of the message input. One of `user`, `assistant`,
            `system`, or

            `developer`.

            '
          enum:
          - user
          - assistant
          - system
          - developer
        content:
          description: 'Text, image, or audio input to the model, used to generate
            a response.

            Can also contain previous assistant responses.

            '
          anyOf:
          - type: string
            title: Text input
            description: 'A text input to the model.

              '
          - $ref: '#/components/schemas/InputMessageContentList'
        type:
          type: string
          description: 'The type of the message input. Always `message`.

            '
          enum:
          - message
          x-stainless-const: true
      required:
      - role
      - content
    FilePath:
      type: object
      title: File path
      description: 'A path to a file.

        '
      properties:
        type:
          type: string
          description: 'The type of the file path. Always `file_path`.

            '
          enum:
          - file_path
          x-stainless-const: true
        file_id:
          type: string
          description: 'The ID of the file.

            '
        index:
          type: integer
          description: 'The index of the file in the list of files.

            '
      required:
      - type
      - file_id
      - index
    FileSearchToolCall:
      type: object
      title: File search tool call
      description: 'The results of a file search tool call. See the

        [file search guide](https://platform.openai.com/docs/guides/tools-file-search)
        for more information.

        '
      properties:
        id:
          type: string
          description: 'The unique ID of the file search tool call.

            '
        type:
          type: string
          enum:
          - file_search_call
          description: 'The type of the file search tool call. Always `file_search_call`.

            '
          x-stainless-const: true
        status:
          type: string
          description: 'The status of the file search tool call. One of `in_progress`,

            `searching`, `incomplete` or `failed`,

            '
          enum:
          - in_progress
          - searching
          - completed
          - incomplete
          - failed
        queries:
          type: array
          items:
            type: string
          description: 'The queries used to search for files.

            '
        results:
          anyOf:
          - type: array
            description: 'The results of the file search tool call.

              '
            items:
              type: object
              properties:
                file_id:
                  type: string
                  description: 'The unique ID of the file.

                    '
                text:
                  type: string
                  description: 'The text that was retrieved from the file.

                    '
                filename:
                  type: string
                  description: 'The name of the file.

                    '
                attributes:
                  $ref: '#/components/schemas/VectorStoreFileAttributes'
                score:
                  type: number
                  format: float
                  description: 'The relevance score of the file - a value between
                    0 and 1.

                    '
          - type: 'null'
      required:
      - id
      - type
      - status
      - queries
    FunctionAndCustomToolCallOutput:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/InputTextContent'
      - $ref: '#/components/schemas/InputImageContent'
      - $ref: '#/components/schemas/InputFileContent'
    FunctionToolCall:
      type: object
      title: Function tool call
      description: "A tool call to run a function. See the \n[function calling guide](https://platform.openai.com/docs/guides/function-calling)\
        \ for more information.\n"
      properties:
        id:
          type: string
          description: 'The unique ID of the function tool call.

            '
        type:
          type: string
          enum:
          - function_call
          description: 'The type of the function tool call. Always `function_call`.

            '
          x-stainless-const: true
        call_id:
          type: string
          description: 'The unique ID of the function tool call generated by the model.

            '
        name:
          type: string
          description: 'The name of the function to run.

            '
        arguments:
          type: string
          description: 'A JSON string of the arguments to pass to the function.

            '
        status:
          type: string
          description: 'The status of the item. One of `in_progress`, `completed`,
            or

            `incomplete`. Populated when items are returned via API.

            '
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - type
      - call_id
      - name
      - arguments
    ImageGenTool:
      type: object
      title: Image generation tool
      description: 'A tool that generates images using a model like `gpt-image-1`.

        '
      properties:
        type:
          type: string
          enum:
          - image_generation
          description: 'The type of the image generation tool. Always `image_generation`.

            '
          x-stainless-const: true
        model:
          type: string
          enum:
          - gpt-image-1
          - gpt-image-1-mini
          description: 'The image generation model to use. Default: `gpt-image-1`.

            '
          default: gpt-image-1
        quality:
          type: string
          enum:
          - low
          - medium
          - high
          - auto
          description: 'The quality of the generated image. One of `low`, `medium`,
            `high`,

            or `auto`. Default: `auto`.

            '
          default: auto
        size:
          type: string
          enum:
          - 1024x1024
          - 1024x1536
          - 1536x1024
          - auto
          description: 'The size of the generated image. One of `1024x1024`, `1024x1536`,

            `1536x1024`, or `auto`. Default: `auto`.

            '
          default: auto
        output_format:
          type: string
          enum:
          - png
          - webp
          - jpeg
          description: 'The output format of the generated image. One of `png`, `webp`,
            or

            `jpeg`. Default: `png`.

            '
          default: png
        output_compression:
          type: integer
          minimum: 0
          maximum: 100
          description: 'Compression level for the output image. Default: 100.

            '
          default: 100
        moderation:
          type: string
          enum:
          - auto
          - low
          description: 'Moderation level for the generated image. Default: `auto`.

            '
          default: auto
        background:
          type: string
          enum:
          - transparent
          - opaque
          - auto
          description: 'Background type for the generated image. One of `transparent`,

            `opaque`, or `auto`. Default: `auto`.

            '
          default: auto
        input_fidelity:
          anyOf:
          - $ref: '#/components/schemas/InputFidelity'
          - type: 'null'
        input_image_mask:
          type: object
          description: 'Optional mask for inpainting. Contains `image_url`

            (string, optional) and `file_id` (string, optional).

            '
          properties:
            image_url:
              type: string
              description: 'Base64-encoded mask image.

                '
            file_id:
              type: string
              description: 'File ID for the mask image.

                '
          required: []
          additionalProperties: false
        partial_images:
          type: integer
          minimum: 0
          maximum: 3
          description: 'Number of partial images to generate in streaming mode, from
            0 (default value) to 3.

            '
          default: 0
      required:
      - type
    ImageGenToolCall:
      type: object
      title: Image generation call
      description: 'An image generation request made by the model.

        '
      properties:
        type:
          type: string
          enum:
          - image_generation_call
          description: 'The type of the image generation call. Always `image_generation_call`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the image generation call.

            '
        status:
          type: string
          enum:
          - in_progress
          - completed
          - generating
          - failed
          description: 'The status of the image generation call.

            '
        result:
          anyOf:
          - type: string
            description: 'The generated image encoded in base64.

              '
          - type: 'null'
      required:
      - type
      - id
      - status
      - result
    InputContent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/InputTextContent'
      - $ref: '#/components/schemas/InputImageContent'
      - $ref: '#/components/schemas/InputFileContent'
    InputItem:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/EasyInputMessage'
      - type: object
        title: Item
        description: 'An item representing part of the context for the response to
          be

          generated by the model. Can contain text, images, and audio inputs,

          as well as previous assistant responses and tool call outputs.

          '
        $ref: '#/components/schemas/Item'
      - $ref: '#/components/schemas/ItemReferenceParam'
    InputMessage:
      type: object
      title: Input message
      description: 'A message input to the model with a role indicating instruction
        following

        hierarchy. Instructions given with the `developer` or `system` role take

        precedence over instructions given with the `user` role.

        '
      properties:
        type:
          type: string
          description: 'The type of the message input. Always set to `message`.

            '
          enum:
          - message
          x-stainless-const: true
        role:
          type: string
          description: 'The role of the message input. One of `user`, `system`, or
            `developer`.

            '
          enum:
          - user
          - system
          - developer
        status:
          type: string
          description: 'The status of item. One of `in_progress`, `completed`, or

            `incomplete`. Populated when items are returned via API.

            '
          enum:
          - in_progress
          - completed
          - incomplete
        content:
          $ref: '#/components/schemas/InputMessageContentList'
      required:
      - role
      - content
    InputMessageContentList:
      type: array
      title: Input item content list
      description: "A list of one or many input items to the model, containing different\
        \ content \ntypes.\n"
      items:
        $ref: '#/components/schemas/InputContent'
    InputParam:
      description: 'Text, image, or file inputs to the model, used to generate a response.


        Learn more:

        - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)

        - [Image inputs](https://platform.openai.com/docs/guides/images)

        - [File inputs](https://platform.openai.com/docs/guides/pdf-files)

        - [Conversation state](https://platform.openai.com/docs/guides/conversation-state)

        - [Function calling](https://platform.openai.com/docs/guides/function-calling)

        '
      anyOf:
      - type: string
        title: Text input
        description: 'A text input to the model, equivalent to a text input with the

          `user` role.

          '
      - type: array
        title: Input item list
        description: 'A list of one or many input items to the model, containing

          different content types.

          '
        items:
          $ref: '#/components/schemas/InputItem'
    Item:
      type: object
      description: 'Content item used to generate a response.

        '
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/InputMessage'
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ComputerCallOutputItemParam'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/FunctionCallOutputItemParam'
      - $ref: '#/components/schemas/ReasoningItem'
      - $ref: '#/components/schemas/ImageGenToolCall'
      - $ref: '#/components/schemas/CodeInterpreterToolCall'
      - $ref: '#/components/schemas/LocalShellToolCall'
      - $ref: '#/components/schemas/LocalShellToolCallOutput'
      - $ref: '#/components/schemas/FunctionShellCallItemParam'
      - $ref: '#/components/schemas/FunctionShellCallOutputItemParam'
      - $ref: '#/components/schemas/ApplyPatchToolCallItemParam'
      - $ref: '#/components/schemas/ApplyPatchToolCallOutputItemParam'
      - $ref: '#/components/schemas/MCPListTools'
      - $ref: '#/components/schemas/MCPApprovalRequest'
      - $ref: '#/components/schemas/MCPApprovalResponse'
      - $ref: '#/components/schemas/MCPToolCall'
      - $ref: '#/components/schemas/CustomToolCallOutput'
      - $ref: '#/components/schemas/CustomToolCall'
    LocalShellToolCall:
      type: object
      title: Local shell call
      description: 'A tool call to run a command on the local shell.

        '
      properties:
        type:
          type: string
          enum:
          - local_shell_call
          description: 'The type of the local shell call. Always `local_shell_call`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the local shell call.

            '
        call_id:
          type: string
          description: 'The unique ID of the local shell tool call generated by the
            model.

            '
        action:
          $ref: '#/components/schemas/LocalShellExecAction'
        status:
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
          description: 'The status of the local shell call.

            '
      required:
      - type
      - id
      - call_id
      - action
      - status
    LocalShellToolCallOutput:
      type: object
      title: Local shell call output
      description: 'The output of a local shell tool call.

        '
      properties:
        type:
          type: string
          enum:
          - local_shell_call_output
          description: 'The type of the local shell tool call output. Always `local_shell_call_output`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the local shell tool call generated by the
            model.

            '
        output:
          type: string
          description: 'A JSON string of the output of the local shell tool call.

            '
        status:
          anyOf:
          - type: string
            enum:
            - in_progress
            - completed
            - incomplete
            description: 'The status of the item. One of `in_progress`, `completed`,
              or `incomplete`.

              '
          - type: 'null'
      required:
      - id
      - type
      - call_id
      - output
    MCPApprovalRequest:
      type: object
      title: MCP approval request
      description: 'A request for human approval of a tool invocation.

        '
      properties:
        type:
          type: string
          enum:
          - mcp_approval_request
          description: 'The type of the item. Always `mcp_approval_request`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the approval request.

            '
        server_label:
          type: string
          description: 'The label of the MCP server making the request.

            '
        name:
          type: string
          description: 'The name of the tool to run.

            '
        arguments:
          type: string
          description: 'A JSON string of arguments for the tool.

            '
      required:
      - type
      - id
      - server_label
      - name
      - arguments
    MCPApprovalResponse:
      type: object
      title: MCP approval response
      description: 'A response to an MCP approval request.

        '
      properties:
        type:
          type: string
          enum:
          - mcp_approval_response
          description: 'The type of the item. Always `mcp_approval_response`.

            '
          x-stainless-const: true
        id:
          anyOf:
          - type: string
            description: 'The unique ID of the approval response

              '
          - type: 'null'
        approval_request_id:
          type: string
          description: 'The ID of the approval request being answered.

            '
        approve:
          type: boolean
          description: 'Whether the request was approved.

            '
        reason:
          anyOf:
          - type: string
            description: 'Optional reason for the decision.

              '
          - type: 'null'
      required:
      - type
      - request_id
      - approve
      - approval_request_id
    MCPListTools:
      type: object
      title: MCP list tools
      description: 'A list of tools available on an MCP server.

        '
      properties:
        type:
          type: string
          enum:
          - mcp_list_tools
          description: 'The type of the item. Always `mcp_list_tools`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the list.

            '
        server_label:
          type: string
          description: 'The label of the MCP server.

            '
        tools:
          type: array
          items:
            $ref: '#/components/schemas/MCPListToolsTool'
          description: 'The tools available on the server.

            '
        error:
          anyOf:
          - type: string
            description: 'Error message if the server could not list tools.

              '
          - type: 'null'
      required:
      - type
      - id
      - server_label
      - tools
    MCPListToolsTool:
      type: object
      title: MCP list tools tool
      description: 'A tool available on an MCP server.

        '
      properties:
        name:
          type: string
          description: 'The name of the tool.

            '
        description:
          anyOf:
          - type: string
            description: 'The description of the tool.

              '
          - type: 'null'
        input_schema:
          type: object
          description: 'The JSON schema describing the tool''s input.

            '
        annotations:
          anyOf:
          - type: object
            description: 'Additional annotations about the tool.

              '
          - type: 'null'
      required:
      - name
      - input_schema
    MCPTool:
      type: object
      title: MCP tool
      description: 'Give the model access to additional tools via remote Model Context
        Protocol

        (MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).

        '
      properties:
        type:
          type: string
          enum:
          - mcp
          description: The type of the MCP tool. Always `mcp`.
          x-stainless-const: true
        server_label:
          type: string
          description: 'A label for this MCP server, used to identify it in tool calls.

            '
        server_url:
          type: string
          description: 'The URL for the MCP server. One of `server_url` or `connector_id`
            must be

            provided.

            '
        connector_id:
          type: string
          enum:
          - connector_dropbox
          - connector_gmail
          - connector_googlecalendar
          - connector_googledrive
          - connector_microsoftteams
          - connector_outlookcalendar
          - connector_outlookemail
          - connector_sharepoint
          description: 'Identifier for service connectors, like those available in
            ChatGPT. One of

            `server_url` or `connector_id` must be provided. Learn more about service

            connectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).


            Currently supported `connector_id` values are:


            - Dropbox: `connector_dropbox`

            - Gmail: `connector_gmail`

            - Google Calendar: `connector_googlecalendar`

            - Google Drive: `connector_googledrive`

            - Microsoft Teams: `connector_microsoftteams`

            - Outlook Calendar: `connector_outlookcalendar`

            - Outlook Email: `connector_outlookemail`

            - SharePoint: `connector_sharepoint`

            '
        authorization:
          type: string
          description: 'An OAuth access token that can be used with a remote MCP server,
            either

            with a custom MCP server URL or a service connector. Your application

            must handle the OAuth authorization flow and provide the token here.

            '
        server_description:
          type: string
          description: 'Optional description of the MCP server, used to provide more
            context.

            '
        headers:
          anyOf:
          - type: object
            additionalProperties:
              type: string
            description: 'Optional HTTP headers to send to the MCP server. Use for
              authentication

              or other purposes.

              '
          - type: 'null'
        allowed_tools:
          anyOf:
          - description: 'List of allowed tool names or a filter object.

              '
            anyOf:
            - type: array
              title: MCP allowed tools
              description: A string array of allowed tool names
              items:
                type: string
            - $ref: '#/components/schemas/MCPToolFilter'
          - type: 'null'
        require_approval:
          anyOf:
          - description: Specify which of the MCP server's tools require approval.
            default: always
            anyOf:
            - type: object
              title: MCP tool approval filter
              description: 'Specify which of the MCP server''s tools require approval.
                Can be

                `always`, `never`, or a filter object associated with tools

                that require approval.

                '
              properties:
                always:
                  $ref: '#/components/schemas/MCPToolFilter'
                never:
                  $ref: '#/components/schemas/MCPToolFilter'
              additionalProperties: false
            - type: string
              title: MCP tool approval setting
              description: 'Specify a single approval policy for all tools. One of
                `always` or

                `never`. When set to `always`, all tools will require approval. When

                set to `never`, all tools will not require approval.

                '
              enum:
              - always
              - never
          - type: 'null'
      required:
      - type
      - server_label
    MCPToolCall:
      type: object
      title: MCP tool call
      description: 'An invocation of a tool on an MCP server.

        '
      properties:
        type:
          type: string
          enum:
          - mcp_call
          description: 'The type of the item. Always `mcp_call`.

            '
          x-stainless-const: true
        id:
          type: string
          description: 'The unique ID of the tool call.

            '
        server_label:
          type: string
          description: 'The label of the MCP server running the tool.

            '
        name:
          type: string
          description: 'The name of the tool that was run.

            '
        arguments:
          type: string
          description: 'A JSON string of the arguments passed to the tool.

            '
        output:
          anyOf:
          - type: string
            description: 'The output from the tool call.

              '
          - type: 'null'
        error:
          anyOf:
          - type: string
            description: 'The error from the tool call, if any.

              '
          - type: 'null'
        status:
          $ref: '#/components/schemas/MCPToolCallStatus'
          description: 'The status of the tool call. One of `in_progress`, `completed`,
            `incomplete`, `calling`, or `failed`.

            '
        approval_request_id:
          anyOf:
          - type: string
            description: 'Unique identifier for the MCP tool call approval request.

              Include this value in a subsequent `mcp_approval_response` input to
              approve or reject the corresponding tool call.

              '
          - type: 'null'
      required:
      - type
      - id
      - server_label
      - name
      - arguments
    MCPToolFilter:
      type: object
      title: MCP tool filter
      description: 'A filter object to specify which tools are allowed.

        '
      properties:
        tool_names:
          type: array
          title: MCP allowed tools
          items:
            type: string
          description: List of allowed tool names.
        read_only:
          type: boolean
          description: 'Indicates whether or not a tool modifies data or is read-only.
            If an

            MCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),

            it will match this filter.

            '
      required: []
      additionalProperties: false
    Metadata:
      anyOf:
      - type: object
        description: 'Set of 16 key-value pairs that can be attached to an object.
          This can be

          useful for storing additional information about the object in a structured

          format, and querying for objects via API or the dashboard.


          Keys are strings with a maximum length of 64 characters. Values are strings

          with a maximum length of 512 characters.

          '
        additionalProperties:
          type: string
        x-oaiTypeLabel: map
      - type: 'null'
    ModelIdsResponses:
      example: gpt-4o
      anyOf:
      - $ref: '#/components/schemas/ModelIdsShared'
      - type: string
        title: ResponsesOnlyModel
        enum:
        - o1-pro
        - o1-pro-2025-03-19
        - o3-pro
        - o3-pro-2025-06-10
        - o3-deep-research
        - o3-deep-research-2025-06-26
        - o4-mini-deep-research
        - o4-mini-deep-research-2025-06-26
        - computer-use-preview
        - computer-use-preview-2025-03-11
        - gpt-5-codex
        - gpt-5-pro
        - gpt-5-pro-2025-10-06
    ModelIdsShared:
      example: gpt-4o
      anyOf:
      - type: string
      - $ref: '#/components/schemas/ChatModel'
    ModelResponseProperties:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        top_logprobs:
          anyOf:
          - description: 'An integer between 0 and 20 specifying the number of most
              likely tokens to

              return at each token position, each with an associated log probability.

              '
            type: integer
            minimum: 0
            maximum: 20
          - type: 'null'
        temperature:
          anyOf:
          - type: number
            minimum: 0
            maximum: 2
            default: 1
            example: 1
            description: 'What sampling temperature to use, between 0 and 2. Higher
              values like 0.8 will make the output more random, while lower values
              like 0.2 will make it more focused and deterministic.

              We generally recommend altering this or `top_p` but not both.

              '
          - type: 'null'
        top_p:
          anyOf:
          - type: number
            minimum: 0
            maximum: 1
            default: 1
            example: 1
            description: 'An alternative to sampling with temperature, called nucleus
              sampling,

              where the model considers the results of the tokens with top_p probability

              mass. So 0.1 means only the tokens comprising the top 10% probability
              mass

              are considered.


              We generally recommend altering this or `temperature` but not both.

              '
          - type: 'null'
        user:
          type: string
          example: user-1234
          deprecated: true
          description: 'This field is being replaced by `safety_identifier` and `prompt_cache_key`.
            Use `prompt_cache_key` instead to maintain caching optimizations.

            A stable identifier for your end-users.

            Used to boost cache hit rates by better bucketing similar requests and  to
            help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).

            '
        safety_identifier:
          type: string
          example: safety-identifier-1234
          description: 'A stable identifier used to help detect users of your application
            that may be violating OpenAI''s usage policies.

            The IDs should be a string that uniquely identifies each user. We recommend
            hashing their username or email address, in order to avoid sending us
            any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).

            '
        prompt_cache_key:
          type: string
          example: prompt-cache-key-1234
          description: 'Used by OpenAI to cache responses for similar requests to
            optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).

            '
        service_tier:
          $ref: '#/components/schemas/ServiceTier'
        prompt_cache_retention:
          anyOf:
          - type: string
            enum:
            - in-memory
            - 24h
            description: 'The retention policy for the prompt cache. Set to `24h`
              to enable extended prompt caching, which keeps cached prefixes active
              for longer, up to a maximum of 24 hours. [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).

              '
          - type: 'null'
    Move:
      type: object
      title: Move
      description: 'A mouse move action.

        '
      properties:
        type:
          type: string
          enum:
          - move
          default: move
          description: "Specifies the event type. For a move action, this property\
            \ is \nalways set to `move`.\n"
          x-stainless-const: true
        x:
          type: integer
          description: 'The x-coordinate to move to.

            '
        y:
          type: integer
          description: 'The y-coordinate to move to.

            '
      required:
      - type
      - x
      - y
    OutputContent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/OutputTextContent'
      - $ref: '#/components/schemas/RefusalContent'
      - $ref: '#/components/schemas/ReasoningTextContent'
    OutputItem:
      anyOf:
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ReasoningItem'
      - $ref: '#/components/schemas/ImageGenToolCall'
      - $ref: '#/components/schemas/CodeInterpreterToolCall'
      - $ref: '#/components/schemas/LocalShellToolCall'
      - $ref: '#/components/schemas/FunctionShellCall'
      - $ref: '#/components/schemas/FunctionShellCallOutput'
      - $ref: '#/components/schemas/ApplyPatchToolCall'
      - $ref: '#/components/schemas/ApplyPatchToolCallOutput'
      - $ref: '#/components/schemas/MCPToolCall'
      - $ref: '#/components/schemas/MCPListTools'
      - $ref: '#/components/schemas/MCPApprovalRequest'
      - $ref: '#/components/schemas/CustomToolCall'
      discriminator:
        propertyName: type
    OutputMessage:
      type: object
      title: Output message
      description: 'An output message from the model.

        '
      properties:
        id:
          type: string
          description: 'The unique ID of the output message.

            '
          x-stainless-go-json: omitzero
        type:
          type: string
          description: 'The type of the output message. Always `message`.

            '
          enum:
          - message
          x-stainless-const: true
        role:
          type: string
          description: 'The role of the output message. Always `assistant`.

            '
          enum:
          - assistant
          x-stainless-const: true
        content:
          type: array
          description: 'The content of the output message.

            '
          items:
            $ref: '#/components/schemas/OutputMessageContent'
        status:
          type: string
          description: 'The status of the message input. One of `in_progress`, `completed`,
            or

            `incomplete`. Populated when input items are returned via API.

            '
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - id
      - type
      - role
      - content
      - status
    OutputMessageContent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/OutputTextContent'
      - $ref: '#/components/schemas/RefusalContent'
    Prompt:
      anyOf:
      - type: object
        description: 'Reference to a prompt template and its variables.

          [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).

          '
        required:
        - id
        properties:
          id:
            type: string
            description: The unique identifier of the prompt template to use.
          version:
            anyOf:
            - type: string
              description: Optional version of the prompt template.
            - type: 'null'
          variables:
            $ref: '#/components/schemas/ResponsePromptVariables'
      - type: 'null'
    Reasoning:
      type: object
      description: '**gpt-5 and o-series models only**


        Configuration options for

        [reasoning models](https://platform.openai.com/docs/guides/reasoning).

        '
      title: Reasoning
      properties:
        effort:
          $ref: '#/components/schemas/ReasoningEffort'
        summary:
          anyOf:
          - type: string
            description: 'A summary of the reasoning performed by the model. This
              can be

              useful for debugging and understanding the model''s reasoning process.

              One of `auto`, `concise`, or `detailed`.


              `concise` is only supported for `computer-use-preview` models.

              '
            enum:
            - auto
            - concise
            - detailed
          - type: 'null'
        generate_summary:
          anyOf:
          - type: string
            deprecated: true
            description: '**Deprecated:** use `summary` instead.


              A summary of the reasoning performed by the model. This can be

              useful for debugging and understanding the model''s reasoning process.

              One of `auto`, `concise`, or `detailed`.

              '
            enum:
            - auto
            - concise
            - detailed
          - type: 'null'
    ReasoningEffort:
      anyOf:
      - type: string
        enum:
        - none
        - minimal
        - low
        - medium
        - high
        default: medium
        description: 'Constrains effort on reasoning for

          [reasoning models](https://platform.openai.com/docs/guides/reasoning).

          Currently supported values are `none`, `minimal`, `low`, `medium`, and `high`.
          Reducing

          reasoning effort can result in faster responses and fewer tokens used

          on reasoning in a response.


          - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported
          reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`.
          Tool calls are supported for all reasoning values in gpt-5.1.

          - All models before `gpt-5.1` default to `medium` reasoning effort, and
          do not support `none`.

          - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning
          effort.

          '
      - type: 'null'
    ReasoningItem:
      type: object
      description: 'A description of the chain of thought used by a reasoning model
        while generating

        a response. Be sure to include these items in your `input` to the Responses
        API

        for subsequent turns of a conversation if you are manually

        [managing context](https://platform.openai.com/docs/guides/conversation-state).

        '
      title: Reasoning
      properties:
        type:
          type: string
          description: 'The type of the object. Always `reasoning`.

            '
          enum:
          - reasoning
          x-stainless-const: true
        id:
          type: string
          description: 'The unique identifier of the reasoning content.

            '
        encrypted_content:
          anyOf:
          - type: string
            description: 'The encrypted content of the reasoning item - populated
              when a response is

              generated with `reasoning.encrypted_content` in the `include` parameter.

              '
          - type: 'null'
        summary:
          type: array
          description: 'Reasoning summary content.

            '
          items:
            $ref: '#/components/schemas/Summary'
        content:
          type: array
          description: 'Reasoning text content.

            '
          items:
            $ref: '#/components/schemas/ReasoningTextContent'
        status:
          type: string
          description: 'The status of the item. One of `in_progress`, `completed`,
            or

            `incomplete`. Populated when items are returned via API.

            '
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - id
      - summary
      - type
    Response:
      title: The response object
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - type: object
        properties:
          id:
            type: string
            description: 'Unique identifier for this Response.

              '
          object:
            type: string
            description: 'The object type of this resource - always set to `response`.

              '
            enum:
            - response
            x-stainless-const: true
          status:
            type: string
            description: 'The status of the response generation. One of `completed`,
              `failed`,

              `in_progress`, `cancelled`, `queued`, or `incomplete`.

              '
            enum:
            - completed
            - failed
            - in_progress
            - cancelled
            - queued
            - incomplete
          created_at:
            type: number
            description: 'Unix timestamp (in seconds) of when this Response was created.

              '
          error:
            $ref: '#/components/schemas/ResponseError'
          incomplete_details:
            anyOf:
            - type: object
              description: 'Details about why the response is incomplete.

                '
              properties:
                reason:
                  type: string
                  description: The reason why the response is incomplete.
                  enum:
                  - max_output_tokens
                  - content_filter
            - type: 'null'
          output:
            type: array
            description: "An array of content items generated by the model.\n\n- The\
              \ length and order of items in the `output` array is dependent\n  on\
              \ the model's response.\n- Rather than accessing the first item in the\
              \ `output` array and\n  assuming it's an `assistant` message with the\
              \ content generated by\n  the model, you might consider using the `output_text`\
              \ property where\n  supported in SDKs.\n"
            items:
              $ref: '#/components/schemas/OutputItem'
          instructions:
            anyOf:
            - description: 'A system (or developer) message inserted into the model''s
                context.


                When using along with `previous_response_id`, the instructions from
                a previous

                response will not be carried over to the next response. This makes
                it simple

                to swap out system (or developer) messages in new responses.

                '
              anyOf:
              - type: string
                description: 'A text input to the model, equivalent to a text input
                  with the

                  `developer` role.

                  '
              - type: array
                title: Input item list
                description: 'A list of one or many input items to the model, containing

                  different content types.

                  '
                items:
                  $ref: '#/components/schemas/InputItem'
            - type: 'null'
          output_text:
            anyOf:
            - type: string
              description: 'SDK-only convenience property that contains the aggregated
                text output

                from all `output_text` items in the `output` array, if any are present.

                Supported in the Python and JavaScript SDKs.

                '
              x-oaiSupportedSDKs:
              - python
              - javascript
            - type: 'null'
            x-stainless-skip: true
          usage:
            $ref: '#/components/schemas/ResponseUsage'
          parallel_tool_calls:
            type: boolean
            description: 'Whether to allow the model to run tool calls in parallel.

              '
            default: true
          conversation:
            anyOf:
            - $ref: '#/components/schemas/Conversation-2'
            - type: 'null'
        required:
        - id
        - object
        - created_at
        - error
        - incomplete_details
        - instructions
        - model
        - tools
        - output
        - parallel_tool_calls
        - metadata
        - tool_choice
        - temperature
        - top_p
    ResponseAudioDeltaEvent:
      type: object
      description: Emitted when there is a partial audio response.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.audio.delta`.

            '
          enum:
          - response.audio.delta
          x-stainless-const: true
        sequence_number:
          type: integer
          description: 'A sequence number for this chunk of the stream response.

            '
        delta:
          type: string
          description: 'A chunk of Base64 encoded response audio bytes.

            '
      required:
      - type
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.audio.delta
        group: responses
        example: "{\n  \"type\": \"response.audio.delta\",\n  \"response_id\": \"\
          resp_123\",\n  \"delta\": \"base64encoded...\",\n  \"sequence_number\":\
          \ 1\n}\n"
    ResponseAudioDoneEvent:
      type: object
      description: Emitted when the audio response is complete.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.audio.done`.

            '
          enum:
          - response.audio.done
          x-stainless-const: true
        sequence_number:
          type: integer
          description: 'The sequence number of the delta.

            '
      required:
      - type
      - sequence_number
      - response_id
      x-oaiMeta:
        name: response.audio.done
        group: responses
        example: "{\n  \"type\": \"response.audio.done\",\n  \"response_id\": \"resp-123\"\
          ,\n  \"sequence_number\": 1\n}\n"
    ResponseAudioTranscriptDeltaEvent:
      type: object
      description: Emitted when there is a partial transcript of audio.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.audio.transcript.delta`.

            '
          enum:
          - response.audio.transcript.delta
          x-stainless-const: true
        delta:
          type: string
          description: 'The partial transcript of the audio response.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - response_id
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.audio.transcript.delta
        group: responses
        example: "{\n  \"type\": \"response.audio.transcript.delta\",\n  \"response_id\"\
          : \"resp_123\",\n  \"delta\": \" ... partial transcript ... \",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseAudioTranscriptDoneEvent:
      type: object
      description: Emitted when the full audio transcript is completed.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.audio.transcript.done`.

            '
          enum:
          - response.audio.transcript.done
          x-stainless-const: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - response_id
      - sequence_number
      x-oaiMeta:
        name: response.audio.transcript.done
        group: responses
        example: "{\n  \"type\": \"response.audio.transcript.done\",\n  \"response_id\"\
          : \"resp_123\",\n  \"sequence_number\": 1\n}\n"
    ResponseCodeInterpreterCallCodeDeltaEvent:
      type: object
      description: Emitted when a partial code snippet is streamed by the code interpreter.
      properties:
        type:
          type: string
          description: The type of the event. Always `response.code_interpreter_call_code.delta`.
          enum:
          - response.code_interpreter_call_code.delta
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response for which the
            code is being streamed.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        delta:
          type: string
          description: The partial code snippet being streamed by the code interpreter.
        sequence_number:
          type: integer
          description: The sequence number of this event, used to order streaming
            events.
      required:
      - type
      - output_index
      - item_id
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.code_interpreter_call_code.delta
        group: responses
        example: "{\n  \"type\": \"response.code_interpreter_call_code.delta\",\n\
          \  \"output_index\": 0,\n  \"item_id\": \"ci_12345\",\n  \"delta\": \"print('Hello,\
          \ world')\",\n  \"sequence_number\": 1\n}\n"
    ResponseCodeInterpreterCallCodeDoneEvent:
      type: object
      description: Emitted when the code snippet is finalized by the code interpreter.
      properties:
        type:
          type: string
          description: The type of the event. Always `response.code_interpreter_call_code.done`.
          enum:
          - response.code_interpreter_call_code.done
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response for which the
            code is finalized.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        code:
          type: string
          description: The final code snippet output by the code interpreter.
        sequence_number:
          type: integer
          description: The sequence number of this event, used to order streaming
            events.
      required:
      - type
      - output_index
      - item_id
      - code
      - sequence_number
      x-oaiMeta:
        name: response.code_interpreter_call_code.done
        group: responses
        example: "{\n  \"type\": \"response.code_interpreter_call_code.done\",\n \
          \ \"output_index\": 3,\n  \"item_id\": \"ci_12345\",\n  \"code\": \"print('done')\"\
          ,\n  \"sequence_number\": 1\n}\n"
    ResponseCodeInterpreterCallCompletedEvent:
      type: object
      description: Emitted when the code interpreter call is completed.
      properties:
        type:
          type: string
          description: The type of the event. Always `response.code_interpreter_call.completed`.
          enum:
          - response.code_interpreter_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response for which the
            code interpreter call is completed.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        sequence_number:
          type: integer
          description: The sequence number of this event, used to order streaming
            events.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.code_interpreter_call.completed
        group: responses
        example: "{\n  \"type\": \"response.code_interpreter_call.completed\",\n \
          \ \"output_index\": 5,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseCodeInterpreterCallInProgressEvent:
      type: object
      description: Emitted when a code interpreter call is in progress.
      properties:
        type:
          type: string
          description: The type of the event. Always `response.code_interpreter_call.in_progress`.
          enum:
          - response.code_interpreter_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response for which the
            code interpreter call is in progress.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        sequence_number:
          type: integer
          description: The sequence number of this event, used to order streaming
            events.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.code_interpreter_call.in_progress
        group: responses
        example: "{\n  \"type\": \"response.code_interpreter_call.in_progress\",\n\
          \  \"output_index\": 0,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseCodeInterpreterCallInterpretingEvent:
      type: object
      description: Emitted when the code interpreter is actively interpreting the
        code snippet.
      properties:
        type:
          type: string
          description: The type of the event. Always `response.code_interpreter_call.interpreting`.
          enum:
          - response.code_interpreter_call.interpreting
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response for which the
            code interpreter is interpreting code.
        item_id:
          type: string
          description: The unique identifier of the code interpreter tool call item.
        sequence_number:
          type: integer
          description: The sequence number of this event, used to order streaming
            events.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.code_interpreter_call.interpreting
        group: responses
        example: "{\n  \"type\": \"response.code_interpreter_call.interpreting\",\n\
          \  \"output_index\": 4,\n  \"item_id\": \"ci_12345\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseCompletedEvent:
      type: object
      description: Emitted when the model response is complete.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.completed`.

            '
          enum:
          - response.completed
          x-stainless-const: true
        response:
          $ref: '#/components/schemas/Response'
          description: 'Properties of the completed response.

            '
        sequence_number:
          type: integer
          description: The sequence number for this event.
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.completed
        group: responses
        example: "{\n  \"type\": \"response.completed\",\n  \"response\": {\n    \"\
          id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\":\
          \ 1740855869,\n    \"status\": \"completed\",\n    \"error\": null,\n  \
          \  \"incomplete_details\": null,\n    \"input\": [],\n    \"instructions\"\
          : null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\"\
          ,\n    \"output\": [\n      {\n        \"id\": \"msg_123\",\n        \"\
          type\": \"message\",\n        \"role\": \"assistant\",\n        \"content\"\
          : [\n          {\n            \"type\": \"output_text\",\n            \"\
          text\": \"In a shimmering forest under a sky full of stars, a lonely unicorn\
          \ named Lila discovered a hidden pond that glowed with moonlight. Every\
          \ night, she would leave sparkling, magical flowers by the water's edge,\
          \ hoping to share her beauty with others. One enchanting evening, she woke\
          \ to find a group of friendly animals gathered around, eager to be friends\
          \ and share in her magic.\",\n            \"annotations\": []\n        \
          \  }\n        ]\n      }\n    ],\n    \"previous_response_id\": null,\n\
          \    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\"\
          : 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n\
          \      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n \
          \   \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": {\n\
          \      \"input_tokens\": 0,\n      \"output_tokens\": 0,\n      \"output_tokens_details\"\
          : {\n        \"reasoning_tokens\": 0\n      },\n      \"total_tokens\":\
          \ 0\n    },\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseContentPartAddedEvent:
      type: object
      description: Emitted when a new content part is added.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.content_part.added`.

            '
          enum:
          - response.content_part.added
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the content part was added
            to.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the content part was added
            to.

            '
        content_index:
          type: integer
          description: 'The index of the content part that was added.

            '
        part:
          $ref: '#/components/schemas/OutputContent'
          description: 'The content part that was added.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - content_index
      - part
      - sequence_number
      x-oaiMeta:
        name: response.content_part.added
        group: responses
        example: "{\n  \"type\": \"response.content_part.added\",\n  \"item_id\":\
          \ \"msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"part\"\
          : {\n    \"type\": \"output_text\",\n    \"text\": \"\",\n    \"annotations\"\
          : []\n  },\n  \"sequence_number\": 1\n}\n"
    ResponseContentPartDoneEvent:
      type: object
      description: Emitted when a content part is done.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.content_part.done`.

            '
          enum:
          - response.content_part.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the content part was added
            to.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the content part was added
            to.

            '
        content_index:
          type: integer
          description: 'The index of the content part that is done.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
        part:
          $ref: '#/components/schemas/OutputContent'
          description: 'The content part that is done.

            '
      required:
      - type
      - item_id
      - output_index
      - content_index
      - part
      - sequence_number
      x-oaiMeta:
        name: response.content_part.done
        group: responses
        example: "{\n  \"type\": \"response.content_part.done\",\n  \"item_id\": \"\
          msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"sequence_number\"\
          : 1,\n  \"part\": {\n    \"type\": \"output_text\",\n    \"text\": \"In\
          \ a shimmering forest under a sky full of stars, a lonely unicorn named\
          \ Lila discovered a hidden pond that glowed with moonlight. Every night,\
          \ she would leave sparkling, magical flowers by the water's edge, hoping\
          \ to share her beauty with others. One enchanting evening, she woke to find\
          \ a group of friendly animals gathered around, eager to be friends and share\
          \ in her magic.\",\n    \"annotations\": []\n  }\n}\n"
    ResponseCreatedEvent:
      type: object
      description: 'An event that is emitted when a response is created.

        '
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.created`.

            '
          enum:
          - response.created
          x-stainless-const: true
        response:
          $ref: '#/components/schemas/Response'
          description: 'The response that was created.

            '
        sequence_number:
          type: integer
          description: The sequence number for this event.
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.created
        group: responses
        example: "{\n  \"type\": \"response.created\",\n  \"response\": {\n    \"\
          id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n    \"\
          object\": \"response\",\n    \"created_at\": 1741487325,\n    \"status\"\
          : \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\": null,\n\
          \    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\"\
          : \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\"\
          : true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n   \
          \   \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n\
          \    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n       \
          \ \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n\
          \    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\"\
          ,\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n\
          \  \"sequence_number\": 1\n}\n"
    ResponseCustomToolCallInputDeltaEvent:
      title: ResponseCustomToolCallInputDelta
      type: object
      description: 'Event representing a delta (partial update) to the input of a
        custom tool call.

        '
      properties:
        type:
          type: string
          enum:
          - response.custom_tool_call_input.delta
          description: The event type identifier.
          x-stainless-const: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
        output_index:
          type: integer
          description: The index of the output this delta applies to.
        item_id:
          type: string
          description: Unique identifier for the API item associated with this event.
        delta:
          type: string
          description: The incremental input data (delta) for the custom tool call.
      required:
      - type
      - output_index
      - item_id
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.custom_tool_call_input.delta
        group: responses
        example: "{\n  \"type\": \"response.custom_tool_call_input.delta\",\n  \"\
          output_index\": 0,\n  \"item_id\": \"ctc_1234567890abcdef\",\n  \"delta\"\
          : \"partial input text\"\n}\n"
    ResponseCustomToolCallInputDoneEvent:
      title: ResponseCustomToolCallInputDone
      type: object
      description: 'Event indicating that input for a custom tool call is complete.

        '
      properties:
        type:
          type: string
          enum:
          - response.custom_tool_call_input.done
          description: The event type identifier.
          x-stainless-const: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
        output_index:
          type: integer
          description: The index of the output this event applies to.
        item_id:
          type: string
          description: Unique identifier for the API item associated with this event.
        input:
          type: string
          description: The complete input data for the custom tool call.
      required:
      - type
      - output_index
      - item_id
      - input
      - sequence_number
      x-oaiMeta:
        name: response.custom_tool_call_input.done
        group: responses
        example: "{\n  \"type\": \"response.custom_tool_call_input.done\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"ctc_1234567890abcdef\",\n  \"input\": \"final complete\
          \ input text\"\n}\n"
    ResponseError:
      anyOf:
      - type: object
        description: 'An error object returned when the model fails to generate a
          Response.

          '
        properties:
          code:
            $ref: '#/components/schemas/ResponseErrorCode'
          message:
            type: string
            description: 'A human-readable description of the error.

              '
        required:
        - code
        - message
      - type: 'null'
    ResponseErrorCode:
      type: string
      description: 'The error code for the response.

        '
      enum:
      - server_error
      - rate_limit_exceeded
      - invalid_prompt
      - vector_store_timeout
      - invalid_image
      - invalid_image_format
      - invalid_base64_image
      - invalid_image_url
      - image_too_large
      - image_too_small
      - image_parse_error
      - image_content_policy_violation
      - invalid_image_mode
      - image_file_too_large
      - unsupported_image_media_type
      - empty_image_file
      - failed_to_download_image
      - image_file_not_found
    ResponseErrorEvent:
      type: object
      description: Emitted when an error occurs.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `error`.

            '
          enum:
          - error
          x-stainless-const: true
        code:
          anyOf:
          - type: string
            description: 'The error code.

              '
          - type: 'null'
        message:
          type: string
          description: 'The error message.

            '
        param:
          anyOf:
          - type: string
            description: 'The error parameter.

              '
          - type: 'null'
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - code
      - message
      - param
      - sequence_number
      x-oaiMeta:
        name: error
        group: responses
        example: "{\n  \"type\": \"error\",\n  \"code\": \"ERR_SOMETHING\",\n  \"\
          message\": \"Something went wrong\",\n  \"param\": null,\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseFailedEvent:
      type: object
      description: 'An event that is emitted when a response fails.

        '
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.failed`.

            '
          enum:
          - response.failed
          x-stainless-const: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
        response:
          $ref: '#/components/schemas/Response'
          description: 'The response that failed.

            '
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.failed
        group: responses
        example: "{\n  \"type\": \"response.failed\",\n  \"response\": {\n    \"id\"\
          : \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n\
          \    \"status\": \"failed\",\n    \"error\": {\n      \"code\": \"server_error\"\
          ,\n      \"message\": \"The model failed to generate a response.\"\n   \
          \ },\n    \"incomplete_details\": null,\n    \"instructions\": null,\n \
          \   \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\"\
          ,\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\"\
          : null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n\
          \      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"\
          tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"\
          truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n\
          \    \"metadata\": {}\n  }\n}\n"
    ResponseFileSearchCallCompletedEvent:
      type: object
      description: Emitted when a file search call is completed (results found).
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.file_search_call.completed`.

            '
          enum:
          - response.file_search_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the file search call is
            initiated.

            '
        item_id:
          type: string
          description: 'The ID of the output item that the file search call is initiated.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.file_search_call.completed
        group: responses
        example: "{\n  \"type\": \"response.file_search_call.completed\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n}\n"
    ResponseFileSearchCallInProgressEvent:
      type: object
      description: Emitted when a file search call is initiated.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.file_search_call.in_progress`.

            '
          enum:
          - response.file_search_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the file search call is
            initiated.

            '
        item_id:
          type: string
          description: 'The ID of the output item that the file search call is initiated.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.file_search_call.in_progress
        group: responses
        example: "{\n  \"type\": \"response.file_search_call.in_progress\",\n  \"\
          output_index\": 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n\
          }\n"
    ResponseFileSearchCallSearchingEvent:
      type: object
      description: Emitted when a file search is currently searching.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.file_search_call.searching`.

            '
          enum:
          - response.file_search_call.searching
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the file search call is
            searching.

            '
        item_id:
          type: string
          description: 'The ID of the output item that the file search call is initiated.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.file_search_call.searching
        group: responses
        example: "{\n  \"type\": \"response.file_search_call.searching\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"fs_123\",\n  \"sequence_number\": 1\n}\n"
    ResponseFormatJsonObject:
      type: object
      title: JSON object
      description: 'JSON object response format. An older method of generating JSON
        responses.

        Using `json_schema` is recommended for models that support it. Note that the

        model will not generate JSON without a system or user message instructing
        it

        to do so.

        '
      properties:
        type:
          type: string
          description: The type of response format being defined. Always `json_object`.
          enum:
          - json_object
          x-stainless-const: true
      required:
      - type
    ResponseFormatJsonSchemaSchema:
      type: object
      title: JSON schema
      description: 'The schema for the response format, described as a JSON Schema
        object.

        Learn how to build JSON schemas [here](https://json-schema.org/).

        '
      additionalProperties: true
    ResponseFormatText:
      type: object
      title: Text
      description: 'Default response format. Used to generate text responses.

        '
      properties:
        type:
          type: string
          description: The type of response format being defined. Always `text`.
          enum:
          - text
          x-stainless-const: true
      required:
      - type
    ResponseFunctionCallArgumentsDeltaEvent:
      type: object
      description: Emitted when there is a partial function-call arguments delta.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.function_call_arguments.delta`.

            '
          enum:
          - response.function_call_arguments.delta
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the function-call arguments
            delta is added to.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the function-call arguments
            delta is added to.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
        delta:
          type: string
          description: 'The function-call arguments delta that is added.

            '
      required:
      - type
      - item_id
      - output_index
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: responses
        example: "{\n  \"type\": \"response.function_call_arguments.delta\",\n  \"\
          item_id\": \"item-abc\",\n  \"output_index\": 0,\n  \"delta\": \"{ \\\"\
          arg\\\":\"\n  \"sequence_number\": 1\n}\n"
    ResponseFunctionCallArgumentsDoneEvent:
      type: object
      description: Emitted when function-call arguments are finalized.
      properties:
        type:
          type: string
          enum:
          - response.function_call_arguments.done
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the item.
        name:
          type: string
          description: The name of the function that was called.
        output_index:
          type: integer
          description: The index of the output item.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        arguments:
          type: string
          description: The function-call arguments.
      required:
      - type
      - item_id
      - name
      - output_index
      - arguments
      - sequence_number
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: responses
        example: "{\n  \"type\": \"response.function_call_arguments.done\",\n  \"\
          item_id\": \"item-abc\",\n  \"name\": \"get_weather\",\n  \"output_index\"\
          : 1,\n  \"arguments\": \"{ \\\"arg\\\": 123 }\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseImageGenCallCompletedEvent:
      type: object
      title: ResponseImageGenCallCompletedEvent
      description: 'Emitted when an image generation tool call has completed and the
        final image is available.

        '
      properties:
        type:
          type: string
          enum:
          - response.image_generation_call.completed
          description: The type of the event. Always 'response.image_generation_call.completed'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.image_generation_call.completed
        group: responses
        example: "{\n  \"type\": \"response.image_generation_call.completed\",\n \
          \ \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseImageGenCallGeneratingEvent:
      type: object
      title: ResponseImageGenCallGeneratingEvent
      description: 'Emitted when an image generation tool call is actively generating
        an image (intermediate state).

        '
      properties:
        type:
          type: string
          enum:
          - response.image_generation_call.generating
          description: The type of the event. Always 'response.image_generation_call.generating'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.image_generation_call.generating
        group: responses
        example: "{\n  \"type\": \"response.image_generation_call.generating\",\n\
          \  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\"\
          : 0\n}\n"
    ResponseImageGenCallInProgressEvent:
      type: object
      title: ResponseImageGenCallInProgressEvent
      description: 'Emitted when an image generation tool call is in progress.

        '
      properties:
        type:
          type: string
          enum:
          - response.image_generation_call.in_progress
          description: The type of the event. Always 'response.image_generation_call.in_progress'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.image_generation_call.in_progress
        group: responses
        example: "{\n  \"type\": \"response.image_generation_call.in_progress\",\n\
          \  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\"\
          : 0\n}\n"
    ResponseImageGenCallPartialImageEvent:
      type: object
      title: ResponseImageGenCallPartialImageEvent
      description: 'Emitted when a partial image is available during image generation
        streaming.

        '
      properties:
        type:
          type: string
          enum:
          - response.image_generation_call.partial_image
          description: The type of the event. Always 'response.image_generation_call.partial_image'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the image generation item being processed.
        sequence_number:
          type: integer
          description: The sequence number of the image generation item being processed.
        partial_image_index:
          type: integer
          description: 0-based index for the partial image (backend is 1-based, but
            this is 0-based for the user).
        partial_image_b64:
          type: string
          description: Base64-encoded partial image data, suitable for rendering as
            an image.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      - partial_image_index
      - partial_image_b64
      x-oaiMeta:
        name: response.image_generation_call.partial_image
        group: responses
        example: "{\n  \"type\": \"response.image_generation_call.partial_image\"\
          ,\n  \"output_index\": 0,\n  \"item_id\": \"item-123\",\n  \"sequence_number\"\
          : 0,\n  \"partial_image_index\": 0,\n  \"partial_image_b64\": \"...\"\n\
          }\n"
    ResponseInProgressEvent:
      type: object
      description: Emitted when the response is in progress.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.in_progress`.

            '
          enum:
          - response.in_progress
          x-stainless-const: true
        response:
          $ref: '#/components/schemas/Response'
          description: 'The response that is in progress.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.in_progress
        group: responses
        example: "{\n  \"type\": \"response.in_progress\",\n  \"response\": {\n  \
          \  \"id\": \"resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c\",\n\
          \    \"object\": \"response\",\n    \"created_at\": 1741487325,\n    \"\
          status\": \"in_progress\",\n    \"error\": null,\n    \"incomplete_details\"\
          : null,\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n\
          \    \"model\": \"gpt-4o-2024-08-06\",\n    \"output\": [],\n    \"parallel_tool_calls\"\
          : true,\n    \"previous_response_id\": null,\n    \"reasoning\": {\n   \
          \   \"effort\": null,\n      \"summary\": null\n    },\n    \"store\": true,\n\
          \    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n       \
          \ \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n\
          \    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\"\
          ,\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n\
          \  \"sequence_number\": 1\n}\n"
    ResponseIncompleteEvent:
      type: object
      description: 'An event that is emitted when a response finishes as incomplete.

        '
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.incomplete`.

            '
          enum:
          - response.incomplete
          x-stainless-const: true
        response:
          $ref: '#/components/schemas/Response'
          description: 'The response that was incomplete.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.incomplete
        group: responses
        example: "{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n   \
          \ \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\"\
          : 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n\
          \    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n\
          \    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\"\
          : \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\"\
          : null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"\
          temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\"\
          : \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\"\
          : [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\"\
          : null,\n    \"user\": null,\n    \"metadata\": {}\n  },\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseLogProb:
      type: object
      description: "A logprob is the logarithmic probability that the model assigns\
        \ to producing \na particular token at a given position in the sequence. Less-negative\
        \ (higher) \nlogprob values indicate greater model confidence in that token\
        \ choice.\n"
      properties:
        token:
          description: A possible text token.
          type: string
        logprob:
          description: 'The log probability of this token.

            '
          type: number
        top_logprobs:
          description: 'The log probability of the top 20 most likely tokens.

            '
          type: array
          items:
            type: object
            properties:
              token:
                description: A possible text token.
                type: string
              logprob:
                description: The log probability of this token.
                type: number
      required:
      - token
      - logprob
    ResponseMCPCallArgumentsDeltaEvent:
      type: object
      title: ResponseMCPCallArgumentsDeltaEvent
      description: 'Emitted when there is a delta (partial update) to the arguments
        of an MCP tool call.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_call_arguments.delta
          description: The type of the event. Always 'response.mcp_call_arguments.delta'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
        delta:
          type: string
          description: 'A JSON string containing the partial update to the arguments
            for the MCP tool call.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - output_index
      - item_id
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.mcp_call_arguments.delta
        group: responses
        example: "{\n  \"type\": \"response.mcp_call_arguments.delta\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"item-abc\",\n  \"delta\": \"{\",\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseMCPCallArgumentsDoneEvent:
      type: object
      title: ResponseMCPCallArgumentsDoneEvent
      description: 'Emitted when the arguments for an MCP tool call are finalized.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_call_arguments.done
          description: The type of the event. Always 'response.mcp_call_arguments.done'.
          x-stainless-const: true
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
        arguments:
          type: string
          description: 'A JSON string containing the finalized arguments for the MCP
            tool call.

            '
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - output_index
      - item_id
      - arguments
      - sequence_number
      x-oaiMeta:
        name: response.mcp_call_arguments.done
        group: responses
        example: "{\n  \"type\": \"response.mcp_call_arguments.done\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"item-abc\",\n  \"arguments\": \"{\\\"arg1\\\": \\\
          \"value1\\\", \\\"arg2\\\": \\\"value2\\\"}\",\n  \"sequence_number\": 1\n\
          }\n"
    ResponseMCPCallCompletedEvent:
      type: object
      title: ResponseMCPCallCompletedEvent
      description: 'Emitted when an MCP  tool call has completed successfully.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_call.completed
          description: The type of the event. Always 'response.mcp_call.completed'.
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the MCP tool call item that completed.
        output_index:
          type: integer
          description: The index of the output item that completed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - sequence_number
      x-oaiMeta:
        name: response.mcp_call.completed
        group: responses
        example: "{\n  \"type\": \"response.mcp_call.completed\",\n  \"sequence_number\"\
          : 1,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\"\
          ,\n  \"output_index\": 0\n}\n"
    ResponseMCPCallFailedEvent:
      type: object
      title: ResponseMCPCallFailedEvent
      description: 'Emitted when an MCP  tool call has failed.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_call.failed
          description: The type of the event. Always 'response.mcp_call.failed'.
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the MCP tool call item that failed.
        output_index:
          type: integer
          description: The index of the output item that failed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - sequence_number
      x-oaiMeta:
        name: response.mcp_call.failed
        group: responses
        example: "{\n  \"type\": \"response.mcp_call.failed\",\n  \"sequence_number\"\
          : 1,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\"\
          ,\n  \"output_index\": 0\n}\n"
    ResponseMCPCallInProgressEvent:
      type: object
      title: ResponseMCPCallInProgressEvent
      description: 'Emitted when an MCP  tool call is in progress.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_call.in_progress
          description: The type of the event. Always 'response.mcp_call.in_progress'.
          x-stainless-const: true
        sequence_number:
          type: integer
          description: The sequence number of this event.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        item_id:
          type: string
          description: The unique identifier of the MCP tool call item being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.mcp_call.in_progress
        group: responses
        example: "{\n  \"type\": \"response.mcp_call.in_progress\",\n  \"sequence_number\"\
          : 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcp_682d437d90a88191bf88cd03aae0c3e503937d5f622d7a90\"\
          \n}\n"
    ResponseMCPListToolsCompletedEvent:
      type: object
      title: ResponseMCPListToolsCompletedEvent
      description: 'Emitted when the list of available MCP tools has been successfully
        retrieved.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_list_tools.completed
          description: The type of the event. Always 'response.mcp_list_tools.completed'.
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the MCP tool call item that produced this output.
        output_index:
          type: integer
          description: The index of the output item that was processed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - sequence_number
      x-oaiMeta:
        name: response.mcp_list_tools.completed
        group: responses
        example: "{\n  \"type\": \"response.mcp_list_tools.completed\",\n  \"sequence_number\"\
          : 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\
          \n}\n"
    ResponseMCPListToolsFailedEvent:
      type: object
      title: ResponseMCPListToolsFailedEvent
      description: 'Emitted when the attempt to list available MCP tools has failed.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_list_tools.failed
          description: The type of the event. Always 'response.mcp_list_tools.failed'.
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the MCP tool call item that failed.
        output_index:
          type: integer
          description: The index of the output item that failed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - sequence_number
      x-oaiMeta:
        name: response.mcp_list_tools.failed
        group: responses
        example: "{\n  \"type\": \"response.mcp_list_tools.failed\",\n  \"sequence_number\"\
          : 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\
          \n}\n"
    ResponseMCPListToolsInProgressEvent:
      type: object
      title: ResponseMCPListToolsInProgressEvent
      description: 'Emitted when the system is in the process of retrieving the list
        of available MCP tools.

        '
      properties:
        type:
          type: string
          enum:
          - response.mcp_list_tools.in_progress
          description: The type of the event. Always 'response.mcp_list_tools.in_progress'.
          x-stainless-const: true
        item_id:
          type: string
          description: The ID of the MCP tool call item that is being processed.
        output_index:
          type: integer
          description: The index of the output item that is being processed.
        sequence_number:
          type: integer
          description: The sequence number of this event.
      required:
      - type
      - item_id
      - output_index
      - sequence_number
      x-oaiMeta:
        name: response.mcp_list_tools.in_progress
        group: responses
        example: "{\n  \"type\": \"response.mcp_list_tools.in_progress\",\n  \"sequence_number\"\
          : 1,\n  \"output_index\": 0,\n  \"item_id\": \"mcpl_682d4379df088191886b70f4ec39f90403937d5f622d7a90\"\
          \n}\n"
    ResponseOutputItemAddedEvent:
      type: object
      description: Emitted when a new output item is added.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.output_item.added`.

            '
          enum:
          - response.output_item.added
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that was added.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
        item:
          $ref: '#/components/schemas/OutputItem'
          description: 'The output item that was added.

            '
      required:
      - type
      - output_index
      - item
      - sequence_number
      x-oaiMeta:
        name: response.output_item.added
        group: responses
        example: "{\n  \"type\": \"response.output_item.added\",\n  \"output_index\"\
          : 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"in_progress\"\
          ,\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\"\
          : []\n  },\n  \"sequence_number\": 1\n}\n"
    ResponseOutputItemDoneEvent:
      type: object
      description: Emitted when an output item is marked done.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.output_item.done`.

            '
          enum:
          - response.output_item.done
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that was marked done.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
        item:
          $ref: '#/components/schemas/OutputItem'
          description: 'The output item that was marked done.

            '
      required:
      - type
      - output_index
      - item
      - sequence_number
      x-oaiMeta:
        name: response.output_item.done
        group: responses
        example: "{\n  \"type\": \"response.output_item.done\",\n  \"output_index\"\
          : 0,\n  \"item\": {\n    \"id\": \"msg_123\",\n    \"status\": \"completed\"\
          ,\n    \"type\": \"message\",\n    \"role\": \"assistant\",\n    \"content\"\
          : [\n      {\n        \"type\": \"output_text\",\n        \"text\": \"In\
          \ a shimmering forest under a sky full of stars, a lonely unicorn named\
          \ Lila discovered a hidden pond that glowed with moonlight. Every night,\
          \ she would leave sparkling, magical flowers by the water's edge, hoping\
          \ to share her beauty with others. One enchanting evening, she woke to find\
          \ a group of friendly animals gathered around, eager to be friends and share\
          \ in her magic.\",\n        \"annotations\": []\n      }\n    ]\n  },\n\
          \  \"sequence_number\": 1\n}\n"
    ResponseOutputTextAnnotationAddedEvent:
      type: object
      title: ResponseOutputTextAnnotationAddedEvent
      description: 'Emitted when an annotation is added to output text content.

        '
      properties:
        type:
          type: string
          enum:
          - response.output_text.annotation.added
          description: The type of the event. Always 'response.output_text.annotation.added'.
          x-stainless-const: true
        item_id:
          type: string
          description: The unique identifier of the item to which the annotation is
            being added.
        output_index:
          type: integer
          description: The index of the output item in the response's output array.
        content_index:
          type: integer
          description: The index of the content part within the output item.
        annotation_index:
          type: integer
          description: The index of the annotation within the content part.
        sequence_number:
          type: integer
          description: The sequence number of this event.
        annotation:
          type: object
          description: The annotation object being added. (See annotation schema for
            details.)
      required:
      - type
      - item_id
      - output_index
      - content_index
      - annotation_index
      - annotation
      - sequence_number
      x-oaiMeta:
        name: response.output_text.annotation.added
        group: responses
        example: "{\n  \"type\": \"response.output_text.annotation.added\",\n  \"\
          item_id\": \"item-abc\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n\
          \  \"annotation_index\": 0,\n  \"annotation\": {\n    \"type\": \"text_annotation\"\
          ,\n    \"text\": \"This is a test annotation\",\n    \"start\": 0,\n   \
          \ \"end\": 10\n  },\n  \"sequence_number\": 1\n}\n"
    ResponsePromptVariables:
      anyOf:
      - type: object
        title: Prompt Variables
        description: 'Optional map of values to substitute in for variables in your

          prompt. The substitution values can either be strings, or other

          Response input types like images or files.

          '
        x-oaiExpandable: true
        x-oaiTypeLabel: map
        additionalProperties:
          x-oaiExpandable: true
          x-oaiTypeLabel: map
          anyOf:
          - type: string
          - $ref: '#/components/schemas/InputTextContent'
          - $ref: '#/components/schemas/InputImageContent'
          - $ref: '#/components/schemas/InputFileContent'
      - type: 'null'
    ResponseProperties:
      type: object
      properties:
        previous_response_id:
          anyOf:
          - type: string
            description: 'The unique ID of the previous response to the model. Use
              this to

              create multi-turn conversations. Learn more about

              [conversation state](https://platform.openai.com/docs/guides/conversation-state).
              Cannot be used in conjunction with `conversation`.

              '
          - type: 'null'
        model:
          description: 'Model ID used to generate the response, like `gpt-4o` or `o3`.
            OpenAI

            offers a wide range of models with different capabilities, performance

            characteristics, and price points. Refer to the [model guide](https://platform.openai.com/docs/models)

            to browse and compare available models.

            '
          $ref: '#/components/schemas/ModelIdsResponses'
        reasoning:
          anyOf:
          - $ref: '#/components/schemas/Reasoning'
          - type: 'null'
        background:
          anyOf:
          - type: boolean
            description: 'Whether to run the model response in the background.

              [Learn more](https://platform.openai.com/docs/guides/background).

              '
            default: false
          - type: 'null'
        max_output_tokens:
          anyOf:
          - description: 'An upper bound for the number of tokens that can be generated
              for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).

              '
            type: integer
          - type: 'null'
        max_tool_calls:
          anyOf:
          - description: 'The maximum number of total calls to built-in tools that
              can be processed in a response. This maximum number applies across all
              built-in tool calls, not per individual tool. Any further attempts to
              call a tool by the model will be ignored.

              '
            type: integer
          - type: 'null'
        text:
          $ref: '#/components/schemas/ResponseTextParam'
        tools:
          $ref: '#/components/schemas/ToolsArray'
        tool_choice:
          $ref: '#/components/schemas/ToolChoiceParam'
        prompt:
          $ref: '#/components/schemas/Prompt'
        truncation:
          anyOf:
          - type: string
            description: "The truncation strategy to use for the model response.\n\
              - `auto`: If the input to this Response exceeds\n  the model's context\
              \ window size, the model will truncate the\n  response to fit the context\
              \ window by dropping items from the beginning of the conversation.\n\
              - `disabled` (default): If the input size will exceed the context window\n\
              \  size for a model, the request will fail with a 400 error.\n"
            enum:
            - auto
            - disabled
            default: disabled
          - type: 'null'
    ResponseQueuedEvent:
      type: object
      title: ResponseQueuedEvent
      description: 'Emitted when a response is queued and waiting to be processed.

        '
      properties:
        type:
          type: string
          enum:
          - response.queued
          description: The type of the event. Always 'response.queued'.
          x-stainless-const: true
        response:
          $ref: '#/components/schemas/Response'
          description: The full response object that is queued.
        sequence_number:
          type: integer
          description: The sequence number for this event.
      required:
      - type
      - response
      - sequence_number
      x-oaiMeta:
        name: response.queued
        group: responses
        example: "{\n  \"type\": \"response.queued\",\n  \"response\": {\n    \"id\"\
          : \"res_123\",\n    \"status\": \"queued\",\n    \"created_at\": \"2021-01-01T00:00:00Z\"\
          ,\n    \"updated_at\": \"2021-01-01T00:00:00Z\"\n  },\n  \"sequence_number\"\
          : 1\n}\n"
    ResponseReasoningSummaryPartAddedEvent:
      type: object
      description: Emitted when a new reasoning summary part is added.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_summary_part.added`.

            '
          enum:
          - response.reasoning_summary_part.added
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this summary part is associated with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this summary part is associated
            with.

            '
        summary_index:
          type: integer
          description: 'The index of the summary part within the reasoning summary.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
        part:
          type: object
          description: 'The summary part that was added.

            '
          properties:
            type:
              type: string
              description: The type of the summary part. Always `summary_text`.
              enum:
              - summary_text
              x-stainless-const: true
            text:
              type: string
              description: The text of the summary part.
          required:
          - type
          - text
      required:
      - type
      - item_id
      - output_index
      - summary_index
      - part
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_summary_part.added
        group: responses
        example: "{\n  \"type\": \"response.reasoning_summary_part.added\",\n  \"\
          item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"\
          output_index\": 0,\n  \"summary_index\": 0,\n  \"part\": {\n    \"type\"\
          : \"summary_text\",\n    \"text\": \"\"\n  },\n  \"sequence_number\": 1\n\
          }\n"
    ResponseReasoningSummaryPartDoneEvent:
      type: object
      description: Emitted when a reasoning summary part is completed.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_summary_part.done`.

            '
          enum:
          - response.reasoning_summary_part.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this summary part is associated with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this summary part is associated
            with.

            '
        summary_index:
          type: integer
          description: 'The index of the summary part within the reasoning summary.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
        part:
          type: object
          description: 'The completed summary part.

            '
          properties:
            type:
              type: string
              description: The type of the summary part. Always `summary_text`.
              enum:
              - summary_text
              x-stainless-const: true
            text:
              type: string
              description: The text of the summary part.
          required:
          - type
          - text
      required:
      - type
      - item_id
      - output_index
      - summary_index
      - part
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_summary_part.done
        group: responses
        example: "{\n  \"type\": \"response.reasoning_summary_part.done\",\n  \"item_id\"\
          : \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\"\
          : 0,\n  \"summary_index\": 0,\n  \"part\": {\n    \"type\": \"summary_text\"\
          ,\n    \"text\": \"**Responding to a greeting**\\n\\nThe user just said,\
          \ \\\"Hello!\\\" So, it seems I need to engage. I'll greet them back and\
          \ offer help since they're looking to chat. I could say something like,\
          \ \\\"Hello! How can I assist you today?\\\" That feels friendly and open.\
          \ They didn't ask a specific question, so this approach will work well for\
          \ starting a conversation. Let's see where it goes from there!\"\n  },\n\
          \  \"sequence_number\": 1\n}\n"
    ResponseReasoningSummaryTextDeltaEvent:
      type: object
      description: Emitted when a delta is added to a reasoning summary text.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_summary_text.delta`.

            '
          enum:
          - response.reasoning_summary_text.delta
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this summary text delta is associated with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this summary text delta is associated
            with.

            '
        summary_index:
          type: integer
          description: 'The index of the summary part within the reasoning summary.

            '
        delta:
          type: string
          description: 'The text delta that was added to the summary.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - summary_index
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_summary_text.delta
        group: responses
        example: "{\n  \"type\": \"response.reasoning_summary_text.delta\",\n  \"\
          item_id\": \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"\
          output_index\": 0,\n  \"summary_index\": 0,\n  \"delta\": \"**Responding\
          \ to a greeting**\\n\\nThe user just said, \\\"Hello!\\\" So, it seems I\
          \ need to engage. I'll greet them back and offer help since they're looking\
          \ to chat. I could say something like, \\\"Hello! How can I assist you today?\\\
          \" That feels friendly and open. They didn't ask a specific question, so\
          \ this approach will work well for starting a conversation. Let's see where\
          \ it goes from there!\",\n  \"sequence_number\": 1\n}\n"
    ResponseReasoningSummaryTextDoneEvent:
      type: object
      description: Emitted when a reasoning summary text is completed.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_summary_text.done`.

            '
          enum:
          - response.reasoning_summary_text.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this summary text is associated with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this summary text is associated
            with.

            '
        summary_index:
          type: integer
          description: 'The index of the summary part within the reasoning summary.

            '
        text:
          type: string
          description: 'The full text of the completed reasoning summary.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - summary_index
      - text
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_summary_text.done
        group: responses
        example: "{\n  \"type\": \"response.reasoning_summary_text.done\",\n  \"item_id\"\
          : \"rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476\",\n  \"output_index\"\
          : 0,\n  \"summary_index\": 0,\n  \"text\": \"**Responding to a greeting**\\\
          n\\nThe user just said, \\\"Hello!\\\" So, it seems I need to engage. I'll\
          \ greet them back and offer help since they're looking to chat. I could\
          \ say something like, \\\"Hello! How can I assist you today?\\\" That feels\
          \ friendly and open. They didn't ask a specific question, so this approach\
          \ will work well for starting a conversation. Let's see where it goes from\
          \ there!\",\n  \"sequence_number\": 1\n}\n"
    ResponseReasoningTextDeltaEvent:
      type: object
      description: Emitted when a delta is added to a reasoning text.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_text.delta`.

            '
          enum:
          - response.reasoning_text.delta
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this reasoning text delta is associated
            with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this reasoning text delta is
            associated with.

            '
        content_index:
          type: integer
          description: 'The index of the reasoning content part this delta is associated
            with.

            '
        delta:
          type: string
          description: 'The text delta that was added to the reasoning content.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - content_index
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_text.delta
        group: responses
        example: "{\n  \"type\": \"response.reasoning_text.delta\",\n  \"item_id\"\
          : \"rs_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\"\
          : \"The\",\n  \"sequence_number\": 1\n}\n"
    ResponseReasoningTextDoneEvent:
      type: object
      description: Emitted when a reasoning text is completed.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.reasoning_text.done`.

            '
          enum:
          - response.reasoning_text.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the item this reasoning text is associated with.

            '
        output_index:
          type: integer
          description: 'The index of the output item this reasoning text is associated
            with.

            '
        content_index:
          type: integer
          description: 'The index of the reasoning content part.

            '
        text:
          type: string
          description: 'The full text of the completed reasoning content.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - content_index
      - text
      - sequence_number
      x-oaiMeta:
        name: response.reasoning_text.done
        group: responses
        example: "{\n  \"type\": \"response.reasoning_text.done\",\n  \"item_id\"\
          : \"rs_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"text\"\
          : \"The user is asking...\",\n  \"sequence_number\": 4\n}\n"
    ResponseRefusalDeltaEvent:
      type: object
      description: Emitted when there is a partial refusal text.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.refusal.delta`.

            '
          enum:
          - response.refusal.delta
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the refusal text is added to.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the refusal text is added
            to.

            '
        content_index:
          type: integer
          description: 'The index of the content part that the refusal text is added
            to.

            '
        delta:
          type: string
          description: 'The refusal text that is added.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - content_index
      - delta
      - sequence_number
      x-oaiMeta:
        name: response.refusal.delta
        group: responses
        example: "{\n  \"type\": \"response.refusal.delta\",\n  \"item_id\": \"msg_123\"\
          ,\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\": \"refusal\
          \ text so far\",\n  \"sequence_number\": 1\n}\n"
    ResponseRefusalDoneEvent:
      type: object
      description: Emitted when refusal text is finalized.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.refusal.done`.

            '
          enum:
          - response.refusal.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the refusal text is finalized.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the refusal text is finalized.

            '
        content_index:
          type: integer
          description: 'The index of the content part that the refusal text is finalized.

            '
        refusal:
          type: string
          description: 'The refusal text that is finalized.

            '
        sequence_number:
          type: integer
          description: 'The sequence number of this event.

            '
      required:
      - type
      - item_id
      - output_index
      - content_index
      - refusal
      - sequence_number
      x-oaiMeta:
        name: response.refusal.done
        group: responses
        example: "{\n  \"type\": \"response.refusal.done\",\n  \"item_id\": \"item-abc\"\
          ,\n  \"output_index\": 1,\n  \"content_index\": 2,\n  \"refusal\": \"final\
          \ refusal text\",\n  \"sequence_number\": 1\n}\n"
    ResponseStreamEvent:
      anyOf:
      - $ref: '#/components/schemas/ResponseAudioDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioDoneEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDeltaEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInterpretingEvent'
      - $ref: '#/components/schemas/ResponseCompletedEvent'
      - $ref: '#/components/schemas/ResponseContentPartAddedEvent'
      - $ref: '#/components/schemas/ResponseContentPartDoneEvent'
      - $ref: '#/components/schemas/ResponseCreatedEvent'
      - $ref: '#/components/schemas/ResponseErrorEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallSearchingEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDeltaEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDoneEvent'
      - $ref: '#/components/schemas/ResponseInProgressEvent'
      - $ref: '#/components/schemas/ResponseFailedEvent'
      - $ref: '#/components/schemas/ResponseIncompleteEvent'
      - $ref: '#/components/schemas/ResponseOutputItemAddedEvent'
      - $ref: '#/components/schemas/ResponseOutputItemDoneEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryPartAddedEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryPartDoneEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseReasoningSummaryTextDoneEvent'
      - $ref: '#/components/schemas/ResponseReasoningTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseReasoningTextDoneEvent'
      - $ref: '#/components/schemas/ResponseRefusalDeltaEvent'
      - $ref: '#/components/schemas/ResponseRefusalDoneEvent'
      - $ref: '#/components/schemas/ResponseTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseTextDoneEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallSearchingEvent'
      - $ref: '#/components/schemas/ResponseImageGenCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseImageGenCallGeneratingEvent'
      - $ref: '#/components/schemas/ResponseImageGenCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseImageGenCallPartialImageEvent'
      - $ref: '#/components/schemas/ResponseMCPCallArgumentsDeltaEvent'
      - $ref: '#/components/schemas/ResponseMCPCallArgumentsDoneEvent'
      - $ref: '#/components/schemas/ResponseMCPCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseMCPCallFailedEvent'
      - $ref: '#/components/schemas/ResponseMCPCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseMCPListToolsCompletedEvent'
      - $ref: '#/components/schemas/ResponseMCPListToolsFailedEvent'
      - $ref: '#/components/schemas/ResponseMCPListToolsInProgressEvent'
      - $ref: '#/components/schemas/ResponseOutputTextAnnotationAddedEvent'
      - $ref: '#/components/schemas/ResponseQueuedEvent'
      - $ref: '#/components/schemas/ResponseCustomToolCallInputDeltaEvent'
      - $ref: '#/components/schemas/ResponseCustomToolCallInputDoneEvent'
      discriminator:
        propertyName: type
    ResponseStreamOptions:
      anyOf:
      - description: 'Options for streaming responses. Only set this when you set
          `stream: true`.

          '
        type: object
        properties:
          include_obfuscation:
            type: boolean
            description: 'When true, stream obfuscation will be enabled. Stream obfuscation
              adds

              random characters to an `obfuscation` field on streaming delta events
              to

              normalize payload sizes as a mitigation to certain side-channel attacks.

              These obfuscation fields are included by default, but add a small amount

              of overhead to the data stream. You can set `include_obfuscation` to

              false to optimize for bandwidth if you trust the network links between

              your application and the OpenAI API.

              '
      - type: 'null'
    ResponseTextDeltaEvent:
      type: object
      description: Emitted when there is an additional text delta.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.output_text.delta`.

            '
          enum:
          - response.output_text.delta
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the text delta was added to.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the text delta was added
            to.

            '
        content_index:
          type: integer
          description: 'The index of the content part that the text delta was added
            to.

            '
        delta:
          type: string
          description: 'The text delta that was added.

            '
        sequence_number:
          type: integer
          description: The sequence number for this event.
        logprobs:
          type: array
          description: 'The log probabilities of the tokens in the delta.

            '
          items:
            $ref: '#/components/schemas/ResponseLogProb'
      required:
      - type
      - item_id
      - output_index
      - content_index
      - delta
      - sequence_number
      - logprobs
      x-oaiMeta:
        name: response.output_text.delta
        group: responses
        example: "{\n  \"type\": \"response.output_text.delta\",\n  \"item_id\": \"\
          msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"delta\"\
          : \"In\",\n  \"sequence_number\": 1\n}\n"
    ResponseTextDoneEvent:
      type: object
      description: Emitted when text content is finalized.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.output_text.done`.

            '
          enum:
          - response.output_text.done
          x-stainless-const: true
        item_id:
          type: string
          description: 'The ID of the output item that the text content is finalized.

            '
        output_index:
          type: integer
          description: 'The index of the output item that the text content is finalized.

            '
        content_index:
          type: integer
          description: 'The index of the content part that the text content is finalized.

            '
        text:
          type: string
          description: 'The text content that is finalized.

            '
        sequence_number:
          type: integer
          description: The sequence number for this event.
        logprobs:
          type: array
          description: 'The log probabilities of the tokens in the delta.

            '
          items:
            $ref: '#/components/schemas/ResponseLogProb'
      required:
      - type
      - item_id
      - output_index
      - content_index
      - text
      - sequence_number
      - logprobs
      x-oaiMeta:
        name: response.output_text.done
        group: responses
        example: "{\n  \"type\": \"response.output_text.done\",\n  \"item_id\": \"\
          msg_123\",\n  \"output_index\": 0,\n  \"content_index\": 0,\n  \"text\"\
          : \"In a shimmering forest under a sky full of stars, a lonely unicorn named\
          \ Lila discovered a hidden pond that glowed with moonlight. Every night,\
          \ she would leave sparkling, magical flowers by the water's edge, hoping\
          \ to share her beauty with others. One enchanting evening, she woke to find\
          \ a group of friendly animals gathered around, eager to be friends and share\
          \ in her magic.\",\n  \"sequence_number\": 1\n}\n"
    ResponseTextParam:
      type: object
      description: 'Configuration options for a text response from the model. Can
        be plain

        text or structured JSON data. Learn more:

        - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)

        - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)

        '
      properties:
        format:
          $ref: '#/components/schemas/TextResponseFormatConfiguration'
        verbosity:
          $ref: '#/components/schemas/Verbosity'
    ResponseUsage:
      type: object
      description: 'Represents token usage details including input tokens, output
        tokens,

        a breakdown of output tokens, and the total tokens used.

        '
      properties:
        input_tokens:
          type: integer
          description: The number of input tokens.
        input_tokens_details:
          type: object
          description: A detailed breakdown of the input tokens.
          properties:
            cached_tokens:
              type: integer
              description: "The number of tokens that were retrieved from the cache.\
                \ \n[More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n"
          required:
          - cached_tokens
        output_tokens:
          type: integer
          description: The number of output tokens.
        output_tokens_details:
          type: object
          description: A detailed breakdown of the output tokens.
          properties:
            reasoning_tokens:
              type: integer
              description: The number of reasoning tokens.
          required:
          - reasoning_tokens
        total_tokens:
          type: integer
          description: The total number of tokens used.
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - output_tokens_details
      - total_tokens
    ResponseWebSearchCallCompletedEvent:
      type: object
      description: Emitted when a web search call is completed.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.web_search_call.completed`.

            '
          enum:
          - response.web_search_call.completed
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the web search call is associated
            with.

            '
        item_id:
          type: string
          description: 'Unique ID for the output item associated with the web search
            call.

            '
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.web_search_call.completed
        group: responses
        example: "{\n  \"type\": \"response.web_search_call.completed\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
    ResponseWebSearchCallInProgressEvent:
      type: object
      description: Emitted when a web search call is initiated.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.web_search_call.in_progress`.

            '
          enum:
          - response.web_search_call.in_progress
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the web search call is associated
            with.

            '
        item_id:
          type: string
          description: 'Unique ID for the output item associated with the web search
            call.

            '
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.web_search_call.in_progress
        group: responses
        example: "{\n  \"type\": \"response.web_search_call.in_progress\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
    ResponseWebSearchCallSearchingEvent:
      type: object
      description: Emitted when a web search call is executing.
      properties:
        type:
          type: string
          description: 'The type of the event. Always `response.web_search_call.searching`.

            '
          enum:
          - response.web_search_call.searching
          x-stainless-const: true
        output_index:
          type: integer
          description: 'The index of the output item that the web search call is associated
            with.

            '
        item_id:
          type: string
          description: 'Unique ID for the output item associated with the web search
            call.

            '
        sequence_number:
          type: integer
          description: The sequence number of the web search call being processed.
      required:
      - type
      - output_index
      - item_id
      - sequence_number
      x-oaiMeta:
        name: response.web_search_call.searching
        group: responses
        example: "{\n  \"type\": \"response.web_search_call.searching\",\n  \"output_index\"\
          : 0,\n  \"item_id\": \"ws_123\",\n  \"sequence_number\": 0\n}\n"
    Screenshot:
      type: object
      title: Screenshot
      description: 'A screenshot action.

        '
      properties:
        type:
          type: string
          enum:
          - screenshot
          default: screenshot
          description: "Specifies the event type. For a screenshot action, this property\
            \ is \nalways set to `screenshot`.\n"
          x-stainless-const: true
      required:
      - type
    Scroll:
      type: object
      title: Scroll
      description: 'A scroll action.

        '
      properties:
        type:
          type: string
          enum:
          - scroll
          default: scroll
          description: "Specifies the event type. For a scroll action, this property\
            \ is \nalways set to `scroll`.\n"
          x-stainless-const: true
        x:
          type: integer
          description: 'The x-coordinate where the scroll occurred.

            '
        y:
          type: integer
          description: 'The y-coordinate where the scroll occurred.

            '
        scroll_x:
          type: integer
          description: 'The horizontal scroll distance.

            '
        scroll_y:
          type: integer
          description: 'The vertical scroll distance.

            '
      required:
      - type
      - x
      - y
      - scroll_x
      - scroll_y
    ServiceTier:
      anyOf:
      - type: string
        description: "Specifies the processing type used for serving the request.\n\
          \  - If set to 'auto', then the request will be processed with the service\
          \ tier configured in the Project settings. Unless otherwise configured,\
          \ the Project will use 'default'.\n  - If set to 'default', then the request\
          \ will be processed with the standard pricing and performance for the selected\
          \ model.\n  - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)'\
          \ or '[priority](https://openai.com/api-priority-processing/)', then the\
          \ request will be processed with the corresponding service tier.\n  - When\
          \ not set, the default behavior is 'auto'.\n\n  When the `service_tier`\
          \ parameter is set, the response body will include the `service_tier` value\
          \ based on the processing mode actually used to serve the request. This\
          \ response value may be different from the value set in the parameter.\n"
        enum:
        - auto
        - default
        - flex
        - scale
        - priority
        default: auto
      - type: 'null'
    TextResponseFormatConfiguration:
      description: "An object specifying the format that the model must output.\n\n\
        Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, \n\
        which ensures the model will match your supplied JSON schema. Learn more in\
        \ the \n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\
        \nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\
        \n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\"\
        : \"json_object\" }` enables the older JSON mode, which\nensures the message\
        \ the model generates is valid JSON. Using `json_schema`\nis preferred for\
        \ models that support it.\n"
      anyOf:
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/TextResponseFormatJsonSchema'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
      discriminator:
        propertyName: type
    TextResponseFormatJsonSchema:
      type: object
      title: JSON schema
      description: 'JSON Schema response format. Used to generate structured JSON
        responses.

        Learn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).

        '
      properties:
        type:
          type: string
          description: The type of response format being defined. Always `json_schema`.
          enum:
          - json_schema
          x-stainless-const: true
        description:
          type: string
          description: 'A description of what the response format is for, used by
            the model to

            determine how to respond in the format.

            '
        name:
          type: string
          description: 'The name of the response format. Must be a-z, A-Z, 0-9, or
            contain

            underscores and dashes, with a maximum length of 64.

            '
        schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
        strict:
          anyOf:
          - type: boolean
            default: false
            description: 'Whether to enable strict schema adherence when generating
              the output.

              If set to true, the model will always follow the exact schema defined

              in the `schema` field. Only a subset of JSON Schema is supported when

              `strict` is `true`. To learn more, read the [Structured Outputs

              guide](https://platform.openai.com/docs/guides/structured-outputs).

              '
          - type: 'null'
      required:
      - type
      - schema
      - name
    Tool:
      description: 'A tool that can be used to generate a response.

        '
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/FunctionTool'
      - $ref: '#/components/schemas/FileSearchTool'
      - $ref: '#/components/schemas/ComputerUsePreviewTool'
      - $ref: '#/components/schemas/WebSearchTool'
      - $ref: '#/components/schemas/MCPTool'
      - $ref: '#/components/schemas/CodeInterpreterTool'
      - $ref: '#/components/schemas/ImageGenTool'
      - $ref: '#/components/schemas/LocalShellToolParam'
      - $ref: '#/components/schemas/FunctionShellToolParam'
      - $ref: '#/components/schemas/CustomToolParam'
      - $ref: '#/components/schemas/WebSearchPreviewTool'
      - $ref: '#/components/schemas/ApplyPatchToolParam'
    ToolChoiceAllowed:
      type: object
      title: Allowed tools
      description: 'Constrains the tools available to the model to a pre-defined set.

        '
      properties:
        type:
          type: string
          enum:
          - allowed_tools
          description: Allowed tool configuration type. Always `allowed_tools`.
          x-stainless-const: true
        mode:
          type: string
          enum:
          - auto
          - required
          description: 'Constrains the tools available to the model to a pre-defined
            set.


            `auto` allows the model to pick from among the allowed tools and generate
            a

            message.


            `required` requires the model to call one or more of the allowed tools.

            '
        tools:
          type: array
          description: "A list of tool definitions that the model should be allowed\
            \ to call.\n\nFor the Responses API, the list of tool definitions might\
            \ look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\"\
            \ },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"\
            type\": \"image_generation\" }\n]\n```\n"
          items:
            type: object
            description: 'A tool definition that the model should be allowed to call.

              '
            additionalProperties: true
            x-oaiExpandable: false
      required:
      - type
      - mode
      - tools
    ToolChoiceCustom:
      type: object
      title: Custom tool
      description: 'Use this option to force the model to call a specific custom tool.

        '
      properties:
        type:
          type: string
          enum:
          - custom
          description: For custom tool calling, the type is always `custom`.
          x-stainless-const: true
        name:
          type: string
          description: The name of the custom tool to call.
      required:
      - type
      - name
    ToolChoiceFunction:
      type: object
      title: Function tool
      description: 'Use this option to force the model to call a specific function.

        '
      properties:
        type:
          type: string
          enum:
          - function
          description: For function calling, the type is always `function`.
          x-stainless-const: true
        name:
          type: string
          description: The name of the function to call.
      required:
      - type
      - name
    ToolChoiceMCP:
      type: object
      title: MCP tool
      description: 'Use this option to force the model to call a specific tool on
        a remote MCP server.

        '
      properties:
        type:
          type: string
          enum:
          - mcp
          description: For MCP tools, the type is always `mcp`.
          x-stainless-const: true
        server_label:
          type: string
          description: 'The label of the MCP server to use.

            '
        name:
          anyOf:
          - type: string
            description: 'The name of the tool to call on the server.

              '
          - type: 'null'
      required:
      - type
      - server_label
    ToolChoiceOptions:
      type: string
      title: Tool choice mode
      description: 'Controls which (if any) tool is called by the model.


        `none` means the model will not call any tool and instead generates a message.


        `auto` means the model can pick between generating a message or calling one
        or

        more tools.


        `required` means the model must call one or more tools.

        '
      enum:
      - none
      - auto
      - required
    ToolChoiceParam:
      description: 'How the model should select which tool (or tools) to use when
        generating

        a response. See the `tools` parameter to see how to specify which tools

        the model can call.

        '
      anyOf:
      - $ref: '#/components/schemas/ToolChoiceOptions'
      - $ref: '#/components/schemas/ToolChoiceAllowed'
      - $ref: '#/components/schemas/ToolChoiceTypes'
      - $ref: '#/components/schemas/ToolChoiceFunction'
      - $ref: '#/components/schemas/ToolChoiceMCP'
      - $ref: '#/components/schemas/ToolChoiceCustom'
      - $ref: '#/components/schemas/SpecificApplyPatchParam'
      - $ref: '#/components/schemas/SpecificFunctionShellParam'
      discriminator:
        propertyName: type
    ToolChoiceTypes:
      type: object
      title: Hosted tool
      description: 'Indicates that the model should use a built-in tool to generate
        a response.

        [Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).

        '
      properties:
        type:
          type: string
          description: 'The type of hosted tool the model should to use. Learn more
            about

            [built-in tools](https://platform.openai.com/docs/guides/tools).


            Allowed values are:

            - `file_search`

            - `web_search_preview`

            - `computer_use_preview`

            - `code_interpreter`

            - `image_generation`

            '
          enum:
          - file_search
          - web_search_preview
          - computer_use_preview
          - web_search_preview_2025_03_11
          - image_generation
          - code_interpreter
      required:
      - type
    ToolsArray:
      type: array
      description: "An array of tools the model may call while generating a response.\
        \ You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\
        \nWe support the following categories of tools:\n- **Built-in tools**: Tools\
        \ that are provided by OpenAI that extend the\n  model's capabilities, like\
        \ [web search](https://platform.openai.com/docs/guides/tools-web-search)\n\
        \  or [file search](https://platform.openai.com/docs/guides/tools-file-search).\
        \ Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n\
        - **MCP Tools**: Integrations with third-party systems via custom MCP servers\n\
        \  or predefined connectors such as Google Drive and SharePoint. Learn more\
        \ about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n\
        - **Function calls (custom tools)**: Functions that are defined by you,\n\
        \  enabling the model to call your own code with strongly typed arguments\n\
        \  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\
        \ You can also use\n  custom tools to call your own code.\n"
      items:
        $ref: '#/components/schemas/Tool'
    Type:
      type: object
      title: Type
      description: 'An action to type in text.

        '
      properties:
        type:
          type: string
          enum:
          - type
          default: type
          description: "Specifies the event type. For a type action, this property\
            \ is \nalways set to `type`.\n"
          x-stainless-const: true
        text:
          type: string
          description: 'The text to type.

            '
      required:
      - type
      - text
    VectorStoreFileAttributes:
      anyOf:
      - type: object
        description: 'Set of 16 key-value pairs that can be attached to an object.
          This can be

          useful for storing additional information about the object in a structured

          format, and querying for objects via API or the dashboard. Keys are strings

          with a maximum length of 64 characters. Values are strings with a maximum

          length of 512 characters, booleans, or numbers.

          '
        maxProperties: 16
        propertyNames:
          type: string
          maxLength: 64
        additionalProperties:
          anyOf:
          - type: string
            maxLength: 512
          - type: number
          - type: boolean
        x-oaiTypeLabel: map
      - type: 'null'
    Verbosity:
      anyOf:
      - type: string
        enum:
        - low
        - medium
        - high
        default: medium
        description: 'Constrains the verbosity of the model''s response. Lower values
          will result in

          more concise responses, while higher values will result in more verbose
          responses.

          Currently supported values are `low`, `medium`, and `high`.

          '
      - type: 'null'
    Wait:
      type: object
      title: Wait
      description: 'A wait action.

        '
      properties:
        type:
          type: string
          enum:
          - wait
          default: wait
          description: "Specifies the event type. For a wait action, this property\
            \ is \nalways set to `wait`.\n"
          x-stainless-const: true
      required:
      - type
    WebSearchActionFind:
      type: object
      title: Find action
      description: 'Action type "find": Searches for a pattern within a loaded page.

        '
      properties:
        type:
          type: string
          enum:
          - find
          description: 'The action type.

            '
          x-stainless-const: true
        url:
          type: string
          format: uri
          description: 'The URL of the page searched for the pattern.

            '
        pattern:
          type: string
          description: 'The pattern or text to search for within the page.

            '
      required:
      - type
      - url
      - pattern
    WebSearchActionOpenPage:
      type: object
      title: Open page action
      description: 'Action type "open_page" - Opens a specific URL from search results.

        '
      properties:
        type:
          type: string
          enum:
          - open_page
          description: 'The action type.

            '
          x-stainless-const: true
        url:
          type: string
          format: uri
          description: 'The URL opened by the model.

            '
      required:
      - type
      - url
    WebSearchActionSearch:
      type: object
      title: Search action
      description: 'Action type "search" - Performs a web search query.

        '
      properties:
        type:
          type: string
          enum:
          - search
          description: 'The action type.

            '
          x-stainless-const: true
        query:
          type: string
          description: 'The search query.

            '
        sources:
          type: array
          title: Web search sources
          description: 'The sources used in the search.

            '
          items:
            type: object
            title: Web search source
            description: 'A source used in the search.

              '
            properties:
              type:
                type: string
                enum:
                - url
                description: 'The type of source. Always `url`.

                  '
                x-stainless-const: true
              url:
                type: string
                description: 'The URL of the source.

                  '
            required:
            - type
            - url
      required:
      - type
      - query
    WebSearchApproximateLocation:
      anyOf:
      - type: object
        title: Web search approximate location
        description: 'The approximate location of the user.

          '
        properties:
          type:
            type: string
            enum:
            - approximate
            description: The type of location approximation. Always `approximate`.
            default: approximate
            x-stainless-const: true
          country:
            anyOf:
            - type: string
              description: The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)
                of the user, e.g. `US`.
            - type: 'null'
          region:
            anyOf:
            - type: string
              description: Free text input for the region of the user, e.g. `California`.
            - type: 'null'
          city:
            anyOf:
            - type: string
              description: Free text input for the city of the user, e.g. `San Francisco`.
            - type: 'null'
          timezone:
            anyOf:
            - type: string
              description: The [IANA timezone](https://timeapi.io/documentation/iana-timezones)
                of the user, e.g. `America/Los_Angeles`.
            - type: 'null'
      - type: 'null'
    WebSearchTool:
      type: object
      title: Web search
      description: 'Search the Internet for sources related to the prompt. Learn more
        about the

        [web search tool](https://platform.openai.com/docs/guides/tools-web-search).

        '
      properties:
        type:
          type: string
          enum:
          - web_search
          - web_search_2025_08_26
          description: The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.
          default: web_search
        filters:
          anyOf:
          - type: object
            description: 'Filters for the search.

              '
            properties:
              allowed_domains:
                anyOf:
                - type: array
                  title: Allowed domains for the search.
                  description: 'Allowed domains for the search. If not provided, all
                    domains are allowed.

                    Subdomains of the provided domains are allowed as well.


                    Example: `["pubmed.ncbi.nlm.nih.gov"]`

                    '
                  items:
                    type: string
                    description: Allowed domain for the search.
                  default: []
                - type: 'null'
          - type: 'null'
        user_location:
          $ref: '#/components/schemas/WebSearchApproximateLocation'
        search_context_size:
          type: string
          enum:
          - low
          - medium
          - high
          default: medium
          description: High level guidance for the amount of context window space
            to use for the search. One of `low`, `medium`, or `high`. `medium` is
            the default.
      required:
      - type
    WebSearchToolCall:
      type: object
      title: Web search tool call
      description: 'The results of a web search tool call. See the

        [web search guide](https://platform.openai.com/docs/guides/tools-web-search)
        for more information.

        '
      properties:
        id:
          type: string
          description: 'The unique ID of the web search tool call.

            '
        type:
          type: string
          enum:
          - web_search_call
          description: 'The type of the web search tool call. Always `web_search_call`.

            '
          x-stainless-const: true
        status:
          type: string
          description: 'The status of the web search tool call.

            '
          enum:
          - in_progress
          - searching
          - completed
          - failed
        action:
          type: object
          description: 'An object describing the specific action taken in this web
            search call.

            Includes details on how the model used the web (search, open_page, find).

            '
          discriminator:
            propertyName: type
          anyOf:
          - $ref: '#/components/schemas/WebSearchActionSearch'
          - $ref: '#/components/schemas/WebSearchActionOpenPage'
          - $ref: '#/components/schemas/WebSearchActionFind'
      required:
      - id
      - type
      - status
      - action
    IncludeEnum:
      type: string
      enum:
      - file_search_call.results
      - web_search_call.results
      - web_search_call.action.sources
      - message.input_image.image_url
      - computer_call_output.output.image_url
      - code_interpreter_call.outputs
      - reasoning.encrypted_content
      - message.output_text.logprobs
      description: 'Specify additional output data to include in the model response.
        Currently supported values are:

        - `web_search_call.action.sources`: Include the sources of the web search
        tool call.

        - `code_interpreter_call.outputs`: Includes the outputs of python code execution
        in code interpreter tool call items.

        - `computer_call_output.output.image_url`: Include image urls from the computer
        call output.

        - `file_search_call.results`: Include the search results of the file search
        tool call.

        - `message.input_image.image_url`: Include image urls from the input message.

        - `message.output_text.logprobs`: Include logprobs with assistant messages.

        - `reasoning.encrypted_content`: Includes an encrypted version of reasoning
        tokens in reasoning item outputs. This enables reasoning items to be used
        in multi-turn conversations when using the Responses API statelessly (like
        when the `store` parameter is set to `false`, or when an organization is enrolled
        in the zero data retention program).'
    InputTextContent:
      properties:
        type:
          type: string
          enum:
          - input_text
          description: The type of the input item. Always `input_text`.
          default: input_text
          x-stainless-const: true
        text:
          type: string
          description: The text input to the model.
      type: object
      required:
      - type
      - text
      title: Input text
      description: A text input to the model.
    FileCitationBody:
      properties:
        type:
          type: string
          enum:
          - file_citation
          description: The type of the file citation. Always `file_citation`.
          default: file_citation
          x-stainless-const: true
        file_id:
          type: string
          description: The ID of the file.
        index:
          type: integer
          description: The index of the file in the list of files.
        filename:
          type: string
          description: The filename of the file cited.
      type: object
      required:
      - type
      - file_id
      - index
      - filename
      title: File citation
      description: A citation to a file.
    UrlCitationBody:
      properties:
        type:
          type: string
          enum:
          - url_citation
          description: The type of the URL citation. Always `url_citation`.
          default: url_citation
          x-stainless-const: true
        url:
          type: string
          description: The URL of the web resource.
        start_index:
          type: integer
          description: The index of the first character of the URL citation in the
            message.
        end_index:
          type: integer
          description: The index of the last character of the URL citation in the
            message.
        title:
          type: string
          description: The title of the web resource.
      type: object
      required:
      - type
      - url
      - start_index
      - end_index
      - title
      title: URL citation
      description: A citation for a web resource used to generate a model response.
    ContainerFileCitationBody:
      properties:
        type:
          type: string
          enum:
          - container_file_citation
          description: The type of the container file citation. Always `container_file_citation`.
          default: container_file_citation
          x-stainless-const: true
        container_id:
          type: string
          description: The ID of the container file.
        file_id:
          type: string
          description: The ID of the file.
        start_index:
          type: integer
          description: The index of the first character of the container file citation
            in the message.
        end_index:
          type: integer
          description: The index of the last character of the container file citation
            in the message.
        filename:
          type: string
          description: The filename of the container file cited.
      type: object
      required:
      - type
      - container_id
      - file_id
      - start_index
      - end_index
      - filename
      title: Container file citation
      description: A citation for a container file used to generate a model response.
    Annotation:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/FileCitationBody'
      - $ref: '#/components/schemas/UrlCitationBody'
      - $ref: '#/components/schemas/ContainerFileCitationBody'
      - $ref: '#/components/schemas/FilePath'
    TopLogProb:
      properties:
        token:
          type: string
        logprob:
          type: number
        bytes:
          items:
            type: integer
          type: array
      type: object
      required:
      - token
      - logprob
      - bytes
      title: Top log probability
      description: The top log probability of a token.
    LogProb:
      properties:
        token:
          type: string
        logprob:
          type: number
        bytes:
          items:
            type: integer
          type: array
        top_logprobs:
          items:
            $ref: '#/components/schemas/TopLogProb'
          type: array
      type: object
      required:
      - token
      - logprob
      - bytes
      - top_logprobs
      title: Log probability
      description: The log probability of a token.
    OutputTextContent:
      properties:
        type:
          type: string
          enum:
          - output_text
          description: The type of the output text. Always `output_text`.
          default: output_text
          x-stainless-const: true
        text:
          type: string
          description: The text output from the model.
        annotations:
          items:
            $ref: '#/components/schemas/Annotation'
          type: array
          description: The annotations of the text output.
        logprobs:
          items:
            $ref: '#/components/schemas/LogProb'
          type: array
      type: object
      required:
      - type
      - text
      - annotations
      title: Output text
      description: A text output from the model.
    ReasoningTextContent:
      properties:
        type:
          type: string
          enum:
          - reasoning_text
          description: The type of the reasoning text. Always `reasoning_text`.
          default: reasoning_text
          x-stainless-const: true
        text:
          type: string
          description: The reasoning text from the model.
      type: object
      required:
      - type
      - text
      title: ReasoningTextContent
      description: Reasoning text from the model.
    RefusalContent:
      properties:
        type:
          type: string
          enum:
          - refusal
          description: The type of the refusal. Always `refusal`.
          default: refusal
          x-stainless-const: true
        refusal:
          type: string
          description: The refusal explanation from the model.
      type: object
      required:
      - type
      - refusal
      title: Refusal
      description: A refusal from the model.
    ImageDetail:
      type: string
      enum:
      - low
      - high
      - auto
    InputImageContent:
      properties:
        type:
          type: string
          enum:
          - input_image
          description: The type of the input item. Always `input_image`.
          default: input_image
          x-stainless-const: true
        image_url:
          anyOf:
          - type: string
            description: The URL of the image to be sent to the model. A fully qualified
              URL or base64 encoded image in a data URL.
          - type: 'null'
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
          - type: 'null'
        detail:
          $ref: '#/components/schemas/ImageDetail'
          description: The detail level of the image to be sent to the model. One
            of `high`, `low`, or `auto`. Defaults to `auto`.
      type: object
      required:
      - type
      - detail
      title: Input image
      description: An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).
    InputFileContent:
      properties:
        type:
          type: string
          enum:
          - input_file
          description: The type of the input item. Always `input_file`.
          default: input_file
          x-stainless-const: true
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
          - type: 'null'
        filename:
          type: string
          description: The name of the file to be sent to the model.
        file_url:
          type: string
          description: The URL of the file to be sent to the model.
        file_data:
          type: string
          description: 'The content of the file to be sent to the model.

            '
      type: object
      required:
      - type
      title: Input file
      description: A file input to the model.
    ClickButtonType:
      type: string
      enum:
      - left
      - right
      - wheel
      - back
      - forward
    ClickParam:
      properties:
        type:
          type: string
          enum:
          - click
          description: Specifies the event type. For a click action, this property
            is always `click`.
          default: click
          x-stainless-const: true
        button:
          $ref: '#/components/schemas/ClickButtonType'
          description: Indicates which mouse button was pressed during the click.
            One of `left`, `right`, `wheel`, `back`, or `forward`.
        x:
          type: integer
          description: The x-coordinate where the click occurred.
        y:
          type: integer
          description: The y-coordinate where the click occurred.
      type: object
      required:
      - type
      - button
      - x
      - y
      title: Click
      description: A click action.
    DoubleClickAction:
      properties:
        type:
          type: string
          enum:
          - double_click
          description: Specifies the event type. For a double click action, this property
            is always set to `double_click`.
          default: double_click
          x-stainless-const: true
        x:
          type: integer
          description: The x-coordinate where the double click occurred.
        y:
          type: integer
          description: The y-coordinate where the double click occurred.
      type: object
      required:
      - type
      - x
      - y
      title: DoubleClick
      description: A double click action.
    DragPoint:
      properties:
        x:
          type: integer
          description: The x-coordinate.
        y:
          type: integer
          description: The y-coordinate.
      type: object
      required:
      - x
      - y
      title: Coordinate
      description: 'An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.'
    KeyPressAction:
      properties:
        type:
          type: string
          enum:
          - keypress
          description: Specifies the event type. For a keypress action, this property
            is always set to `keypress`.
          default: keypress
          x-stainless-const: true
        keys:
          items:
            type: string
            description: One of the keys the model is requesting to be pressed.
          type: array
          description: The combination of keys the model is requesting to be pressed.
            This is an array of strings, each representing a key.
      type: object
      required:
      - type
      - keys
      title: KeyPress
      description: A collection of keypresses the model would like to perform.
    ComputerCallSafetyCheckParam:
      properties:
        id:
          type: string
          description: The ID of the pending safety check.
        code:
          anyOf:
          - type: string
            description: The type of the pending safety check.
          - type: 'null'
        message:
          anyOf:
          - type: string
            description: Details about the pending safety check.
          - type: 'null'
      type: object
      required:
      - id
      description: A pending safety check for the computer call.
    CodeInterpreterOutputLogs:
      properties:
        type:
          type: string
          enum:
          - logs
          description: The type of the output. Always `logs`.
          default: logs
          x-stainless-const: true
        logs:
          type: string
          description: The logs output from the code interpreter.
      type: object
      required:
      - type
      - logs
      title: Code interpreter output logs
      description: The logs output from the code interpreter.
    CodeInterpreterOutputImage:
      properties:
        type:
          type: string
          enum:
          - image
          description: The type of the output. Always `image`.
          default: image
          x-stainless-const: true
        url:
          type: string
          description: The URL of the image output from the code interpreter.
      type: object
      required:
      - type
      - url
      title: Code interpreter output image
      description: The image output from the code interpreter.
    LocalShellExecAction:
      properties:
        type:
          type: string
          enum:
          - exec
          description: The type of the local shell action. Always `exec`.
          default: exec
          x-stainless-const: true
        command:
          items:
            type: string
          type: array
          description: The command to run.
        timeout_ms:
          anyOf:
          - type: integer
            description: Optional timeout in milliseconds for the command.
          - type: 'null'
        working_directory:
          anyOf:
          - type: string
            description: Optional working directory to run the command in.
          - type: 'null'
        env:
          additionalProperties:
            type: string
          type: object
          description: Environment variables to set for the command.
          x-oaiTypeLabel: map
        user:
          anyOf:
          - type: string
            description: Optional user to run the command as.
          - type: 'null'
      type: object
      required:
      - type
      - command
      - env
      title: Local shell exec action
      description: Execute a shell command on the server.
    FunctionShellAction:
      properties:
        commands:
          items:
            type: string
            description: A list of commands to run.
          type: array
        timeout_ms:
          anyOf:
          - type: integer
            description: Optional timeout in milliseconds for the commands.
          - type: 'null'
        max_output_length:
          anyOf:
          - type: integer
            description: Optional maximum number of characters to return from each
              command.
          - type: 'null'
      type: object
      required:
      - commands
      - timeout_ms
      - max_output_length
      title: Shell exec action
      description: Execute a shell command.
    LocalShellCallStatus:
      type: string
      enum:
      - in_progress
      - completed
      - incomplete
    FunctionShellCall:
      properties:
        type:
          type: string
          enum:
          - shell_call
          description: The type of the item. Always `shell_call`.
          default: shell_call
          x-stainless-const: true
        id:
          type: string
          description: The unique ID of the function shell tool call. Populated when
            this item is returned via API.
        call_id:
          type: string
          description: The unique ID of the function shell tool call generated by
            the model.
        action:
          $ref: '#/components/schemas/FunctionShellAction'
          description: The shell commands and limits that describe how to run the
            tool call.
        status:
          $ref: '#/components/schemas/LocalShellCallStatus'
          description: The status of the shell call. One of `in_progress`, `completed`,
            or `incomplete`.
        created_by:
          type: string
          description: The ID of the entity that created this tool call.
      type: object
      required:
      - type
      - id
      - call_id
      - action
      - status
      title: Function shell tool call
      description: A tool call that executes one or more shell commands in a managed
        environment.
    FunctionShellCallOutputTimeoutOutcome:
      properties:
        type:
          type: string
          enum:
          - timeout
          description: The outcome type. Always `timeout`.
          default: timeout
          x-stainless-const: true
      type: object
      required:
      - type
      title: Function shell timeout outcome
      description: Indicates that the function shell call exceeded its configured
        time limit.
    FunctionShellCallOutputExitOutcome:
      properties:
        type:
          type: string
          enum:
          - exit
          description: The outcome type. Always `exit`.
          default: exit
          x-stainless-const: true
        exit_code:
          type: integer
          description: Exit code from the shell process.
      type: object
      required:
      - type
      - exit_code
      title: Function shell exit outcome
      description: Indicates that the shell commands finished and returned an exit
        code.
    FunctionShellCallOutputContent:
      properties:
        stdout:
          type: string
        stderr:
          type: string
        outcome:
          title: Function shell call outcome
          description: Represents either an exit outcome (with an exit code) or a
            timeout outcome for a shell call output chunk.
          discriminator:
            propertyName: type
          anyOf:
          - $ref: '#/components/schemas/FunctionShellCallOutputTimeoutOutcome'
          - $ref: '#/components/schemas/FunctionShellCallOutputExitOutcome'
        created_by:
          type: string
      type: object
      required:
      - stdout
      - stderr
      - outcome
      title: Shell call output content
      description: The content of a shell call output.
    FunctionShellCallOutput:
      properties:
        type:
          type: string
          enum:
          - shell_call_output
          description: The type of the shell call output. Always `shell_call_output`.
          default: shell_call_output
          x-stainless-const: true
        id:
          type: string
          description: The unique ID of the shell call output. Populated when this
            item is returned via API.
        call_id:
          type: string
          description: The unique ID of the shell tool call generated by the model.
        output:
          items:
            $ref: '#/components/schemas/FunctionShellCallOutputContent'
          type: array
          description: An array of shell call output contents
        max_output_length:
          anyOf:
          - type: integer
            description: The maximum length of the shell command output. This is generated
              by the model and should be passed back with the raw output.
          - type: 'null'
        created_by:
          type: string
      type: object
      required:
      - type
      - id
      - call_id
      - output
      - max_output_length
      title: Shell call output
      description: The output of a shell tool call.
    ApplyPatchCallStatus:
      type: string
      enum:
      - in_progress
      - completed
    ApplyPatchCreateFileOperation:
      properties:
        type:
          type: string
          enum:
          - create_file
          description: Create a new file with the provided diff.
          default: create_file
          x-stainless-const: true
        path:
          type: string
          description: Path of the file to create.
        diff:
          type: string
          description: Diff to apply.
      type: object
      required:
      - type
      - path
      - diff
      title: Apply patch create file operation
      description: Instruction describing how to create a file via the apply_patch
        tool.
    ApplyPatchDeleteFileOperation:
      properties:
        type:
          type: string
          enum:
          - delete_file
          description: Delete the specified file.
          default: delete_file
          x-stainless-const: true
        path:
          type: string
          description: Path of the file to delete.
      type: object
      required:
      - type
      - path
      title: Apply patch delete file operation
      description: Instruction describing how to delete a file via the apply_patch
        tool.
    ApplyPatchUpdateFileOperation:
      properties:
        type:
          type: string
          enum:
          - update_file
          description: Update an existing file with the provided diff.
          default: update_file
          x-stainless-const: true
        path:
          type: string
          description: Path of the file to update.
        diff:
          type: string
          description: Diff to apply.
      type: object
      required:
      - type
      - path
      - diff
      title: Apply patch update file operation
      description: Instruction describing how to update a file via the apply_patch
        tool.
    ApplyPatchToolCall:
      properties:
        type:
          type: string
          enum:
          - apply_patch_call
          description: The type of the item. Always `apply_patch_call`.
          default: apply_patch_call
          x-stainless-const: true
        id:
          type: string
          description: The unique ID of the apply patch tool call. Populated when
            this item is returned via API.
        call_id:
          type: string
          description: The unique ID of the apply patch tool call generated by the
            model.
        status:
          $ref: '#/components/schemas/ApplyPatchCallStatus'
          description: The status of the apply patch tool call. One of `in_progress`
            or `completed`.
        operation:
          title: Apply patch operation
          description: One of the create_file, delete_file, or update_file operations
            applied via apply_patch.
          discriminator:
            propertyName: type
          anyOf:
          - $ref: '#/components/schemas/ApplyPatchCreateFileOperation'
          - $ref: '#/components/schemas/ApplyPatchDeleteFileOperation'
          - $ref: '#/components/schemas/ApplyPatchUpdateFileOperation'
        created_by:
          type: string
          description: The ID of the entity that created this tool call.
      type: object
      required:
      - type
      - id
      - call_id
      - status
      - operation
      title: Apply patch tool call
      description: A tool call that applies file diffs by creating, deleting, or updating
        files.
    ApplyPatchCallOutputStatus:
      type: string
      enum:
      - completed
      - failed
    ApplyPatchToolCallOutput:
      properties:
        type:
          type: string
          enum:
          - apply_patch_call_output
          description: The type of the item. Always `apply_patch_call_output`.
          default: apply_patch_call_output
          x-stainless-const: true
        id:
          type: string
          description: The unique ID of the apply patch tool call output. Populated
            when this item is returned via API.
        call_id:
          type: string
          description: The unique ID of the apply patch tool call generated by the
            model.
        status:
          $ref: '#/components/schemas/ApplyPatchCallOutputStatus'
          description: The status of the apply patch tool call output. One of `completed`
            or `failed`.
        output:
          anyOf:
          - type: string
            description: Optional textual output returned by the apply patch tool.
          - type: 'null'
        created_by:
          type: string
          description: The ID of the entity that created this tool call output.
      type: object
      required:
      - type
      - id
      - call_id
      - status
      title: Apply patch tool call output
      description: The output emitted by an apply patch tool call.
    MCPToolCallStatus:
      type: string
      enum:
      - in_progress
      - completed
      - incomplete
      - calling
      - failed
    DetailEnum:
      type: string
      enum:
      - low
      - high
      - auto
    FunctionCallItemStatus:
      type: string
      enum:
      - in_progress
      - completed
      - incomplete
    ComputerCallOutputItemParam:
      properties:
        id:
          anyOf:
          - type: string
            description: The ID of the computer tool call output.
            example: cuo_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The ID of the computer tool call that produced the output.
        type:
          type: string
          enum:
          - computer_call_output
          description: The type of the computer tool call output. Always `computer_call_output`.
          default: computer_call_output
          x-stainless-const: true
        output:
          $ref: '#/components/schemas/ComputerScreenshotImage'
        acknowledged_safety_checks:
          anyOf:
          - items:
              $ref: '#/components/schemas/ComputerCallSafetyCheckParam'
            type: array
            description: The safety checks reported by the API that have been acknowledged
              by the developer.
          - type: 'null'
        status:
          anyOf:
          - $ref: '#/components/schemas/FunctionCallItemStatus'
            description: The status of the message input. One of `in_progress`, `completed`,
              or `incomplete`. Populated when input items are returned via API.
          - type: 'null'
      type: object
      required:
      - call_id
      - type
      - output
      title: Computer tool call output
      description: The output of a computer tool call.
    InputTextContentParam:
      properties:
        type:
          type: string
          enum:
          - input_text
          description: The type of the input item. Always `input_text`.
          default: input_text
          x-stainless-const: true
        text:
          type: string
          maxLength: 10485760
          description: The text input to the model.
      type: object
      required:
      - type
      - text
      title: Input text
      description: A text input to the model.
    InputImageContentParamAutoParam:
      properties:
        type:
          type: string
          enum:
          - input_image
          description: The type of the input item. Always `input_image`.
          default: input_image
          x-stainless-const: true
        image_url:
          anyOf:
          - type: string
            maxLength: 20971520
            description: The URL of the image to be sent to the model. A fully qualified
              URL or base64 encoded image in a data URL.
          - type: 'null'
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
            example: file-123
          - type: 'null'
        detail:
          anyOf:
          - $ref: '#/components/schemas/DetailEnum'
            description: The detail level of the image to be sent to the model. One
              of `high`, `low`, or `auto`. Defaults to `auto`.
          - type: 'null'
      type: object
      required:
      - type
      title: Input image
      description: An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)
    InputFileContentParam:
      properties:
        type:
          type: string
          enum:
          - input_file
          description: The type of the input item. Always `input_file`.
          default: input_file
          x-stainless-const: true
        file_id:
          anyOf:
          - type: string
            description: The ID of the file to be sent to the model.
            example: file-123
          - type: 'null'
        filename:
          anyOf:
          - type: string
            description: The name of the file to be sent to the model.
          - type: 'null'
        file_data:
          anyOf:
          - type: string
            maxLength: 33554432
            description: The base64-encoded data of the file to be sent to the model.
          - type: 'null'
        file_url:
          anyOf:
          - type: string
            description: The URL of the file to be sent to the model.
          - type: 'null'
      type: object
      required:
      - type
      title: Input file
      description: A file input to the model.
    FunctionCallOutputItemParam:
      properties:
        id:
          anyOf:
          - type: string
            description: The unique ID of the function tool call output. Populated
              when this item is returned via API.
            example: fc_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The unique ID of the function tool call generated by the model.
        type:
          type: string
          enum:
          - function_call_output
          description: The type of the function tool call output. Always `function_call_output`.
          default: function_call_output
          x-stainless-const: true
        output:
          description: Text, image, or file output of the function tool call.
          anyOf:
          - type: string
            maxLength: 10485760
            description: A JSON string of the output of the function tool call.
          - items:
              discriminator:
                propertyName: type
              anyOf:
              - $ref: '#/components/schemas/InputTextContentParam'
              - $ref: '#/components/schemas/InputImageContentParamAutoParam'
              - $ref: '#/components/schemas/InputFileContentParam'
            type: array
        status:
          anyOf:
          - $ref: '#/components/schemas/FunctionCallItemStatus'
            description: The status of the item. One of `in_progress`, `completed`,
              or `incomplete`. Populated when items are returned via API.
          - type: 'null'
      type: object
      required:
      - call_id
      - type
      - output
      title: Function tool call output
      description: The output of a function tool call.
    FunctionShellActionParam:
      properties:
        commands:
          items:
            type: string
          type: array
          description: Ordered shell commands for the execution environment to run.
        timeout_ms:
          anyOf:
          - type: integer
            description: Maximum wall-clock time in milliseconds to allow the shell
              commands to run.
          - type: 'null'
        max_output_length:
          anyOf:
          - type: integer
            description: Maximum number of UTF-8 characters to capture from combined
              stdout and stderr output.
          - type: 'null'
      type: object
      required:
      - commands
      title: Function shell action
      description: Commands and limits describing how to run the function shell tool
        call.
    FunctionShellCallItemStatus:
      type: string
      enum:
      - in_progress
      - completed
      - incomplete
      title: Function shell call status
      description: Status values reported for function shell tool calls.
    FunctionShellCallItemParam:
      properties:
        id:
          anyOf:
          - type: string
            description: The unique ID of the function shell tool call. Populated
              when this item is returned via API.
            example: sh_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The unique ID of the function shell tool call generated by
            the model.
        type:
          type: string
          enum:
          - shell_call
          description: The type of the item. Always `function_shell_call`.
          default: shell_call
          x-stainless-const: true
        action:
          $ref: '#/components/schemas/FunctionShellActionParam'
          description: The shell commands and limits that describe how to run the
            tool call.
        status:
          anyOf:
          - $ref: '#/components/schemas/FunctionShellCallItemStatus'
            description: The status of the shell call. One of `in_progress`, `completed`,
              or `incomplete`.
          - type: 'null'
      type: object
      required:
      - call_id
      - type
      - action
      title: Function shell tool call
      description: A tool representing a request to execute one or more shell commands.
    FunctionShellCallOutputTimeoutOutcomeParam:
      properties:
        type:
          type: string
          enum:
          - timeout
          description: The outcome type. Always `timeout`.
          default: timeout
          x-stainless-const: true
      type: object
      required:
      - type
      title: Function shell timeout outcome
      description: Indicates that the function shell call exceeded its configured
        time limit.
    FunctionShellCallOutputExitOutcomeParam:
      properties:
        type:
          type: string
          enum:
          - exit
          description: The outcome type. Always `exit`.
          default: exit
          x-stainless-const: true
        exit_code:
          type: integer
          description: The exit code returned by the shell process.
      type: object
      required:
      - type
      - exit_code
      title: Function shell exit outcome
      description: Indicates that the shell commands finished and returned an exit
        code.
    FunctionShellCallOutputOutcomeParam:
      title: Function shell call outcome
      description: The exit or timeout outcome associated with this chunk.
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/FunctionShellCallOutputTimeoutOutcomeParam'
      - $ref: '#/components/schemas/FunctionShellCallOutputExitOutcomeParam'
    FunctionShellCallOutputContentParam:
      properties:
        stdout:
          type: string
          maxLength: 10485760
          description: Captured stdout output for this chunk of the shell call.
        stderr:
          type: string
          maxLength: 10485760
          description: Captured stderr output for this chunk of the shell call.
        outcome:
          $ref: '#/components/schemas/FunctionShellCallOutputOutcomeParam'
          description: The exit or timeout outcome associated with this chunk.
      type: object
      required:
      - stdout
      - stderr
      - outcome
      title: Function shell output chunk
      description: Captured stdout and stderr for a portion of a function shell tool
        call output.
    FunctionShellCallOutputItemParam:
      properties:
        id:
          anyOf:
          - type: string
            description: The unique ID of the function shell tool call output. Populated
              when this item is returned via API.
            example: sho_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The unique ID of the function shell tool call generated by
            the model.
        type:
          type: string
          enum:
          - shell_call_output
          description: The type of the item. Always `function_shell_call_output`.
          default: shell_call_output
          x-stainless-const: true
        output:
          items:
            $ref: '#/components/schemas/FunctionShellCallOutputContentParam'
          type: array
          description: Captured chunks of stdout and stderr output, along with their
            associated outcomes.
        max_output_length:
          anyOf:
          - type: integer
            description: The maximum number of UTF-8 characters captured for this
              shell call's combined output.
          - type: 'null'
      type: object
      required:
      - call_id
      - type
      - output
      title: Function shell tool call output
      description: The streamed output items emitted by a function shell tool call.
    ApplyPatchCallStatusParam:
      type: string
      enum:
      - in_progress
      - completed
      title: Apply patch call status
      description: Status values reported for apply_patch tool calls.
    ApplyPatchCreateFileOperationParam:
      properties:
        type:
          type: string
          enum:
          - create_file
          description: The operation type. Always `create_file`.
          default: create_file
          x-stainless-const: true
        path:
          type: string
          minLength: 1
          description: Path of the file to create relative to the workspace root.
        diff:
          type: string
          maxLength: 10485760
          description: Unified diff content to apply when creating the file.
      type: object
      required:
      - type
      - path
      - diff
      title: Apply patch create file operation
      description: Instruction for creating a new file via the apply_patch tool.
    ApplyPatchDeleteFileOperationParam:
      properties:
        type:
          type: string
          enum:
          - delete_file
          description: The operation type. Always `delete_file`.
          default: delete_file
          x-stainless-const: true
        path:
          type: string
          minLength: 1
          description: Path of the file to delete relative to the workspace root.
      type: object
      required:
      - type
      - path
      title: Apply patch delete file operation
      description: Instruction for deleting an existing file via the apply_patch tool.
    ApplyPatchUpdateFileOperationParam:
      properties:
        type:
          type: string
          enum:
          - update_file
          description: The operation type. Always `update_file`.
          default: update_file
          x-stainless-const: true
        path:
          type: string
          minLength: 1
          description: Path of the file to update relative to the workspace root.
        diff:
          type: string
          maxLength: 10485760
          description: Unified diff content to apply to the existing file.
      type: object
      required:
      - type
      - path
      - diff
      title: Apply patch update file operation
      description: Instruction for updating an existing file via the apply_patch tool.
    ApplyPatchOperationParam:
      title: Apply patch operation
      description: One of the create_file, delete_file, or update_file operations
        supplied to the apply_patch tool.
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/ApplyPatchCreateFileOperationParam'
      - $ref: '#/components/schemas/ApplyPatchDeleteFileOperationParam'
      - $ref: '#/components/schemas/ApplyPatchUpdateFileOperationParam'
    ApplyPatchToolCallItemParam:
      properties:
        type:
          type: string
          enum:
          - apply_patch_call
          description: The type of the item. Always `apply_patch_call`.
          default: apply_patch_call
          x-stainless-const: true
        id:
          anyOf:
          - type: string
            description: The unique ID of the apply patch tool call. Populated when
              this item is returned via API.
            example: apc_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The unique ID of the apply patch tool call generated by the
            model.
        status:
          $ref: '#/components/schemas/ApplyPatchCallStatusParam'
          description: The status of the apply patch tool call. One of `in_progress`
            or `completed`.
        operation:
          $ref: '#/components/schemas/ApplyPatchOperationParam'
          description: The specific create, delete, or update instruction for the
            apply_patch tool call.
      type: object
      required:
      - type
      - call_id
      - status
      - operation
      title: Apply patch tool call
      description: A tool call representing a request to create, delete, or update
        files using diff patches.
    ApplyPatchCallOutputStatusParam:
      type: string
      enum:
      - completed
      - failed
      title: Apply patch call output status
      description: Outcome values reported for apply_patch tool call outputs.
    ApplyPatchToolCallOutputItemParam:
      properties:
        type:
          type: string
          enum:
          - apply_patch_call_output
          description: The type of the item. Always `apply_patch_call_output`.
          default: apply_patch_call_output
          x-stainless-const: true
        id:
          anyOf:
          - type: string
            description: The unique ID of the apply patch tool call output. Populated
              when this item is returned via API.
            example: apco_123
          - type: 'null'
        call_id:
          type: string
          maxLength: 64
          minLength: 1
          description: The unique ID of the apply patch tool call generated by the
            model.
        status:
          $ref: '#/components/schemas/ApplyPatchCallOutputStatusParam'
          description: The status of the apply patch tool call output. One of `completed`
            or `failed`.
        output:
          anyOf:
          - type: string
            maxLength: 10485760
            description: Optional human-readable log text from the apply patch tool
              (e.g., patch results or errors).
          - type: 'null'
      type: object
      required:
      - type
      - call_id
      - status
      title: Apply patch tool call output
      description: The streamed output emitted by an apply patch tool call.
    ItemReferenceParam:
      properties:
        type:
          anyOf:
          - type: string
            enum:
            - item_reference
            description: The type of item to reference. Always `item_reference`.
            default: item_reference
            x-stainless-const: true
          - type: 'null'
        id:
          type: string
          description: The ID of the item to reference.
      type: object
      required:
      - id
      title: Item reference
      description: An internal identifier for an item to reference.
    FunctionTool:
      properties:
        type:
          type: string
          enum:
          - function
          description: The type of the function tool. Always `function`.
          default: function
          x-stainless-const: true
        name:
          type: string
          description: The name of the function to call.
        description:
          anyOf:
          - type: string
            description: A description of the function. Used by the model to determine
              whether or not to call the function.
          - type: 'null'
        parameters:
          anyOf:
          - additionalProperties: {}
            type: object
            description: A JSON schema object describing the parameters of the function.
            x-oaiTypeLabel: map
          - type: 'null'
        strict:
          anyOf:
          - type: boolean
            description: Whether to enforce strict parameter validation. Default `true`.
          - type: 'null'
      type: object
      required:
      - type
      - name
      - strict
      - parameters
      title: Function
      description: Defines a function in your own code the model can choose to call.
        Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).
    RankerVersionType:
      type: string
      enum:
      - auto
      - default-2024-11-15
    HybridSearchOptions:
      properties:
        embedding_weight:
          type: number
          description: The weight of the embedding in the reciprocal ranking fusion.
        text_weight:
          type: number
          description: The weight of the text in the reciprocal ranking fusion.
      type: object
      required:
      - embedding_weight
      - text_weight
    RankingOptions:
      properties:
        ranker:
          $ref: '#/components/schemas/RankerVersionType'
          description: The ranker to use for the file search.
        score_threshold:
          type: number
          description: The score threshold for the file search, a number between 0
            and 1. Numbers closer to 1 will attempt to return only the most relevant
            results, but may return fewer results.
        hybrid_search:
          $ref: '#/components/schemas/HybridSearchOptions'
          description: Weights that control how reciprocal rank fusion balances semantic
            embedding matches versus sparse keyword matches when hybrid search is
            enabled.
      type: object
      required: []
    Filters:
      anyOf:
      - $ref: '#/components/schemas/ComparisonFilter'
      - $ref: '#/components/schemas/CompoundFilter'
    FileSearchTool:
      properties:
        type:
          type: string
          enum:
          - file_search
          description: The type of the file search tool. Always `file_search`.
          default: file_search
          x-stainless-const: true
        vector_store_ids:
          items:
            type: string
          type: array
          description: The IDs of the vector stores to search.
        max_num_results:
          type: integer
          description: The maximum number of results to return. This number should
            be between 1 and 50 inclusive.
        ranking_options:
          $ref: '#/components/schemas/RankingOptions'
          description: Ranking options for search.
        filters:
          anyOf:
          - $ref: '#/components/schemas/Filters'
            description: A filter to apply.
          - type: 'null'
      type: object
      required:
      - type
      - vector_store_ids
      title: File search
      description: A tool that searches for relevant content from uploaded files.
        Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).
    ComputerEnvironment:
      type: string
      enum:
      - windows
      - mac
      - linux
      - ubuntu
      - browser
    ComputerUsePreviewTool:
      properties:
        type:
          type: string
          enum:
          - computer_use_preview
          description: The type of the computer use tool. Always `computer_use_preview`.
          default: computer_use_preview
          x-stainless-const: true
        environment:
          $ref: '#/components/schemas/ComputerEnvironment'
          description: The type of computer environment to control.
        display_width:
          type: integer
          description: The width of the computer display.
        display_height:
          type: integer
          description: The height of the computer display.
      type: object
      required:
      - type
      - environment
      - display_width
      - display_height
      title: Computer use preview
      description: A tool that controls a virtual computer. Learn more about the [computer
        tool](https://platform.openai.com/docs/guides/tools-computer-use).
    ContainerMemoryLimit:
      type: string
      enum:
      - 1g
      - 4g
      - 16g
      - 64g
    InputFidelity:
      type: string
      enum:
      - high
      - low
      description: Control how much effort the model will exert to match the style
        and features, especially facial features, of input images. This parameter
        is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports
        `high` and `low`. Defaults to `low`.
    LocalShellToolParam:
      properties:
        type:
          type: string
          enum:
          - local_shell
          description: The type of the local shell tool. Always `local_shell`.
          default: local_shell
          x-stainless-const: true
      type: object
      required:
      - type
      title: Local shell tool
      description: A tool that allows the model to execute shell commands in a local
        environment.
    FunctionShellToolParam:
      properties:
        type:
          type: string
          enum:
          - shell
          description: The type of the shell tool. Always `shell`.
          default: shell
          x-stainless-const: true
      type: object
      required:
      - type
      title: Shell tool
      description: A tool that allows the model to execute shell commands.
    CustomTextFormatParam:
      properties:
        type:
          type: string
          enum:
          - text
          description: Unconstrained text format. Always `text`.
          default: text
          x-stainless-const: true
      type: object
      required:
      - type
      title: Text format
      description: Unconstrained free-form text.
    GrammarSyntax1:
      type: string
      enum:
      - lark
      - regex
    CustomGrammarFormatParam:
      properties:
        type:
          type: string
          enum:
          - grammar
          description: Grammar format. Always `grammar`.
          default: grammar
          x-stainless-const: true
        syntax:
          $ref: '#/components/schemas/GrammarSyntax1'
          description: The syntax of the grammar definition. One of `lark` or `regex`.
        definition:
          type: string
          description: The grammar definition.
      type: object
      required:
      - type
      - syntax
      - definition
      title: Grammar format
      description: A grammar defined by the user.
    CustomToolParam:
      properties:
        type:
          type: string
          enum:
          - custom
          description: The type of the custom tool. Always `custom`.
          default: custom
          x-stainless-const: true
        name:
          type: string
          description: The name of the custom tool, used to identify it in tool calls.
        description:
          type: string
          description: Optional description of the custom tool, used to provide more
            context.
        format:
          description: The input format for the custom tool. Default is unconstrained
            text.
          discriminator:
            propertyName: type
          anyOf:
          - $ref: '#/components/schemas/CustomTextFormatParam'
          - $ref: '#/components/schemas/CustomGrammarFormatParam'
      type: object
      required:
      - type
      - name
      title: Custom tool
      description: A custom tool that processes input using a specified format. Learn
        more about   [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)
    ApproximateLocation:
      properties:
        type:
          type: string
          enum:
          - approximate
          description: The type of location approximation. Always `approximate`.
          default: approximate
          x-stainless-const: true
        country:
          anyOf:
          - type: string
            description: The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1)
              of the user, e.g. `US`.
          - type: 'null'
        region:
          anyOf:
          - type: string
            description: Free text input for the region of the user, e.g. `California`.
          - type: 'null'
        city:
          anyOf:
          - type: string
            description: Free text input for the city of the user, e.g. `San Francisco`.
          - type: 'null'
        timezone:
          anyOf:
          - type: string
            description: The [IANA timezone](https://timeapi.io/documentation/iana-timezones)
              of the user, e.g. `America/Los_Angeles`.
          - type: 'null'
      type: object
      required:
      - type
    SearchContextSize:
      type: string
      enum:
      - low
      - medium
      - high
    WebSearchPreviewTool:
      properties:
        type:
          type: string
          enum:
          - web_search_preview
          - web_search_preview_2025_03_11
          description: The type of the web search tool. One of `web_search_preview`
            or `web_search_preview_2025_03_11`.
          default: web_search_preview
          x-stainless-const: true
        user_location:
          anyOf:
          - $ref: '#/components/schemas/ApproximateLocation'
            description: The user's location.
          - type: 'null'
        search_context_size:
          $ref: '#/components/schemas/SearchContextSize'
          description: High level guidance for the amount of context window space
            to use for the search. One of `low`, `medium`, or `high`. `medium` is
            the default.
      type: object
      required:
      - type
      title: Web search preview
      description: This tool searches the web for relevant results to use in a response.
        Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).
    ApplyPatchToolParam:
      properties:
        type:
          type: string
          enum:
          - apply_patch
          description: The type of the tool. Always `apply_patch`.
          default: apply_patch
          x-stainless-const: true
      type: object
      required:
      - type
      title: Apply patch tool
      description: Allows the assistant to create, delete, or update files using unified
        diffs.
    SpecificApplyPatchParam:
      properties:
        type:
          type: string
          enum:
          - apply_patch
          description: The tool to call. Always `apply_patch`.
          default: apply_patch
          x-stainless-const: true
      type: object
      required:
      - type
      title: Specific apply patch tool choice
      description: Forces the model to call the apply_patch tool when executing a
        tool call.
    SpecificFunctionShellParam:
      properties:
        type:
          type: string
          enum:
          - shell
          description: The tool to call. Always `shell`.
          default: shell
          x-stainless-const: true
      type: object
      required:
      - type
      title: Specific shell tool choice
      description: Forces the model to call the function shell tool when a tool call
        is required.
    ConversationParam-2:
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
          example: conv_123
      type: object
      required:
      - id
      title: Conversation object
      description: The conversation that this response belongs to.
    Conversation-2:
      properties:
        id:
          type: string
          description: The unique ID of the conversation.
      type: object
      required:
      - id
      title: Conversation
      description: The conversation that this response belongs to. Input items and
        output items from this response are automatically added to this conversation.
    ComparisonFilterValueItems:
      anyOf:
      - type: string
      - type: number
    ChatModel:
      type: string
      enum:
      - gpt-5.1
      - gpt-5.1-2025-11-13
      - gpt-5.1-codex
      - gpt-5.1-mini
      - gpt-5.1-chat-latest
      - gpt-5
      - gpt-5-mini
      - gpt-5-nano
      - gpt-5-2025-08-07
      - gpt-5-mini-2025-08-07
      - gpt-5-nano-2025-08-07
      - gpt-5-chat-latest
      - gpt-4.1
      - gpt-4.1-mini
      - gpt-4.1-nano
      - gpt-4.1-2025-04-14
      - gpt-4.1-mini-2025-04-14
      - gpt-4.1-nano-2025-04-14
      - o4-mini
      - o4-mini-2025-04-16
      - o3
      - o3-2025-04-16
      - o3-mini
      - o3-mini-2025-01-31
      - o1
      - o1-2024-12-17
      - o1-preview
      - o1-preview-2024-09-12
      - o1-mini
      - o1-mini-2024-09-12
      - gpt-4o
      - gpt-4o-2024-11-20
      - gpt-4o-2024-08-06
      - gpt-4o-2024-05-13
      - gpt-4o-audio-preview
      - gpt-4o-audio-preview-2024-10-01
      - gpt-4o-audio-preview-2024-12-17
      - gpt-4o-audio-preview-2025-06-03
      - gpt-4o-mini-audio-preview
      - gpt-4o-mini-audio-preview-2024-12-17
      - gpt-4o-search-preview
      - gpt-4o-mini-search-preview
      - gpt-4o-search-preview-2025-03-11
      - gpt-4o-mini-search-preview-2025-03-11
      - chatgpt-4o-latest
      - codex-mini-latest
      - gpt-4o-mini
      - gpt-4o-mini-2024-07-18
      - gpt-4-turbo
      - gpt-4-turbo-2024-04-09
      - gpt-4-0125-preview
      - gpt-4-turbo-preview
      - gpt-4-1106-preview
      - gpt-4-vision-preview
      - gpt-4
      - gpt-4-0314
      - gpt-4-0613
      - gpt-4-32k
      - gpt-4-32k-0314
      - gpt-4-32k-0613
      - gpt-3.5-turbo
      - gpt-3.5-turbo-16k
      - gpt-3.5-turbo-0301
      - gpt-3.5-turbo-0613
      - gpt-3.5-turbo-1106
      - gpt-3.5-turbo-0125
      - gpt-3.5-turbo-16k-0613
      x-stainless-nominal: false
    Summary:
      properties:
        type:
          type: string
          enum:
          - summary_text
          description: The type of the object. Always `summary_text`.
          default: summary_text
          x-stainless-const: true
        text:
          type: string
          description: A summary of the reasoning output from the model so far.
      type: object
      required:
      - type
      - text
      title: Summary text
      description: A summary text from the model.
    CodeInterpreterContainerAuto:
      properties:
        type:
          type: string
          enum:
          - auto
          description: Always `auto`.
          default: auto
          x-stainless-const: true
        file_ids:
          items:
            type: string
            example: file-123
          type: array
          maxItems: 50
          description: An optional list of uploaded files to make available to your
            code.
        memory_limit:
          anyOf:
          - $ref: '#/components/schemas/ContainerMemoryLimit'
          - type: 'null'
      type: object
      required:
      - type
      title: CodeInterpreterToolAuto
      description: Configuration for a code interpreter container. Optionally specify
        the IDs of the files to run the code on.
      x-stainless-naming:
        go:
          type_name: ToolCodeInterpreterContainerCodeInterpreterContainerAuto
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
security:
- ApiKeyAuth: []
